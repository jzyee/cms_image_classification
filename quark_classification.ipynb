{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quark_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI5RDzjpY4fy",
        "colab_type": "text"
      },
      "source": [
        "#notebook setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH7ZObaXX2it",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b3aea8f9-3fee-4728-c0d6-073d7abc39ba"
      },
      "source": [
        "!pip install -qq tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 395.5MB 21kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 2.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 6.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tb-nightly 2.1.0a20191206 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C7NHc2JYy9U",
        "colab_type": "code",
        "outputId": "c896a21d-faf2-42e0-e808-f4afac8b4bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.8.1\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.0.0\n",
            "asgiref==3.2.3\n",
            "astor==0.8.1\n",
            "astropy==3.0.5\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.3.0\n",
            "attrs==19.3.0\n",
            "audioread==2.1.8\n",
            "autograd==1.3\n",
            "Babel==2.7.0\n",
            "backcall==0.1.0\n",
            "backports.tempfile==1.0\n",
            "backports.weakref==1.0.post1\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.1.0\n",
            "blis==0.2.4\n",
            "bokeh==1.0.4\n",
            "boto==2.49.0\n",
            "boto3==1.10.40\n",
            "botocore==1.13.40\n",
            "Bottleneck==1.3.1\n",
            "branca==0.3.1\n",
            "bs4==0.0.1\n",
            "bz2file==0.98\n",
            "cachetools==4.0.0\n",
            "certifi==2019.11.28\n",
            "cffi==1.13.2\n",
            "chainer==6.5.0\n",
            "chardet==3.0.4\n",
            "chart-studio==1.0.0\n",
            "Click==7.0\n",
            "cloudpickle==1.2.2\n",
            "cmake==3.12.0\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.2.0\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.0\n",
            "cupy-cuda101==6.5.0\n",
            "cvxopt==1.2.3\n",
            "cvxpy==1.0.25\n",
            "cycler==0.10.0\n",
            "cymem==2.0.3\n",
            "Cython==0.29.14\n",
            "daft==0.0.4\n",
            "dask==1.1.5\n",
            "dataclasses==0.7\n",
            "datascience==0.10.6\n",
            "decorator==4.4.1\n",
            "defusedxml==0.6.0\n",
            "descartes==1.1.0\n",
            "dill==0.3.1.1\n",
            "distributed==1.25.3\n",
            "Django==3.0\n",
            "dlib==19.18.0\n",
            "dm-sonnet==1.35\n",
            "docopt==0.6.2\n",
            "docutils==0.15.2\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.208\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.1.0\n",
            "entrypoints==0.3\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.59\n",
            "fastcache==1.1.0\n",
            "fastdtw==0.3.4\n",
            "fastprogress==0.1.22\n",
            "fastrlock==0.4\n",
            "fbprophet==0.5\n",
            "feather-format==0.4.0\n",
            "featuretools==0.4.1\n",
            "filelock==3.0.12\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.1\n",
            "folium==0.8.3\n",
            "fsspec==0.6.2\n",
            "future==0.16.0\n",
            "gast==0.2.2\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gevent==1.4.0\n",
            "gin-config==0.2.1\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.15.0\n",
            "google-api-python-client==1.7.11\n",
            "google-auth==1.10.0\n",
            "google-auth-httplib2==0.0.3\n",
            "google-auth-oauthlib==0.4.1\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.16.2\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.1.8\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.6.0\n",
            "googledrivedownloader==0.4\n",
            "graph-nets==1.0.5\n",
            "graphviz==0.10.1\n",
            "greenlet==0.4.15\n",
            "grpcio==1.15.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.3\n",
            "gunicorn==20.0.4\n",
            "gym==0.15.4\n",
            "h5py==2.8.0\n",
            "HeapDict==1.0.1\n",
            "holidays==0.9.11\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.11.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.8\n",
            "image==1.5.27\n",
            "imageio==2.4.1\n",
            "imagesize==1.1.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==1.3.0\n",
            "imutils==0.5.3\n",
            "inflect==2.1.0\n",
            "intel-openmp==2020.0.133\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.6.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.5.1\n",
            "itsdangerous==1.1.0\n",
            "jax==0.1.52\n",
            "jaxlib==0.1.36\n",
            "jdcal==1.4.1\n",
            "jedi==0.15.1\n",
            "jieba==0.39\n",
            "Jinja2==2.10.3\n",
            "jmespath==0.9.4\n",
            "joblib==0.14.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.4\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.6.1\n",
            "kaggle==1.5.6\n",
            "kapre==0.1.3.1\n",
            "Keras==2.2.5\n",
            "Keras-Applications==1.0.8\n",
            "Keras-Preprocessing==1.1.0\n",
            "keras-vis==0.4.1\n",
            "kfac==0.2.0\n",
            "kiwisolver==1.1.0\n",
            "knnimpute==0.1.0\n",
            "librosa==0.6.3\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.30.0\n",
            "lmdb==0.98\n",
            "lucid==0.3.8\n",
            "lunardate==0.2.0\n",
            "lxml==4.2.6\n",
            "magenta==0.3.19\n",
            "Markdown==3.1.1\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.1.2\n",
            "matplotlib-venn==0.11.5\n",
            "mesh-tensorflow==0.1.7\n",
            "mido==1.2.6\n",
            "mir-eval==0.5\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.5.4\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.0.2\n",
            "moviepy==0.2.3.5\n",
            "mpi4py==3.0.3\n",
            "mpmath==1.1.0\n",
            "msgpack==0.5.6\n",
            "multiprocess==0.70.9\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.2\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbconvert==5.6.1\n",
            "nbformat==4.4.0\n",
            "networkx==2.4\n",
            "nibabel==2.3.3\n",
            "nltk==3.2.5\n",
            "notebook==5.2.2\n",
            "np-utils==0.5.12.1\n",
            "numba==0.40.1\n",
            "numexpr==2.7.0\n",
            "numpy==1.17.4\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "olefile==0.46\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.1.0\n",
            "osqp==0.6.1\n",
            "packaging==19.2\n",
            "palettable==3.3.0\n",
            "pandas==0.25.3\n",
            "pandas-datareader==0.7.4\n",
            "pandas-gbq==0.11.0\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.2\n",
            "parso==0.5.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.7.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==4.3.0\n",
            "pip-tools==4.2.0\n",
            "plac==0.9.6\n",
            "plotly==4.1.1\n",
            "plotnine==0.5.1\n",
            "pluggy==0.7.1\n",
            "portpicker==1.2.0\n",
            "prefetch-generator==1.0.1\n",
            "preshed==2.0.1\n",
            "pretty-midi==0.2.8\n",
            "prettytable==0.7.2\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.7.1\n",
            "promise==2.2.1\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.10.0\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.6.0\n",
            "py==1.8.0\n",
            "pyarrow==0.14.1\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.7\n",
            "pycocotools==2.0.0\n",
            "pycparser==2.19\n",
            "pydata-google-auth==0.2.1\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyglet==1.3.2\n",
            "Pygments==2.1.3\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "PyMeeus==0.3.6\n",
            "pymongo==3.10.0\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.4\n",
            "pyparsing==2.4.5\n",
            "pypng==0.0.20\n",
            "pyrsistent==0.15.6\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==1.6.4\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.6.1\n",
            "python-louvain==0.13\n",
            "python-rtmidi==1.3.1\n",
            "python-slugify==4.0.0\n",
            "python-utils==2.3.0\n",
            "pytz==2018.9\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==17.0.0\n",
            "qtconsole==4.6.0\n",
            "regex==2019.12.9\n",
            "requests==2.21.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==2.9.5\n",
            "rsa==4.0\n",
            "s3fs==0.4.0\n",
            "s3transfer==0.2.1\n",
            "scikit-image==0.15.0\n",
            "scikit-learn==0.21.3\n",
            "scipy==1.3.3\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.1.post2\n",
            "seaborn==0.9.0\n",
            "semantic-version==2.8.3\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.6.4.post2\n",
            "simplegeneric==0.8.1\n",
            "six==1.12.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==1.9.0\n",
            "snowballstemmer==2.0.0\n",
            "sortedcontainers==2.1.0\n",
            "spacy==2.1.9\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-websupport==1.1.2\n",
            "SQLAlchemy==1.3.12\n",
            "sqlparse==0.3.0\n",
            "srsly==0.2.0\n",
            "stable-baselines==2.2.1\n",
            "statsmodels==0.10.2\n",
            "sympy==1.1.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.6\n",
            "tb-nightly==2.1.0a20191206\n",
            "tblib==1.6.0\n",
            "tensor2tensor==1.14.1\n",
            "tensorboard==1.15.0\n",
            "tensorboardcolab==0.0.22\n",
            "tensorflow==1.15.0\n",
            "tensorflow-datasets==1.3.2\n",
            "tensorflow-estimator==1.15.1\n",
            "tensorflow-estimator-2.0-preview==2.0.0\n",
            "tensorflow-gan==2.0.0\n",
            "tensorflow-hub==0.7.0\n",
            "tensorflow-metadata==0.15.1\n",
            "tensorflow-privacy==0.2.2\n",
            "tensorflow-probability==0.7.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.8.3\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "tf-nightly-gpu-2.0-preview==2.0.0.dev20191002\n",
            "tflearn==0.3.2\n",
            "Theano==1.0.4\n",
            "thinc==7.0.8\n",
            "toolz==0.10.0\n",
            "torch==1.3.1\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.4.2\n",
            "tornado==4.5.3\n",
            "tqdm==4.28.1\n",
            "traitlets==4.3.3\n",
            "tweepy==3.6.0\n",
            "typing==3.6.6\n",
            "typing-extensions==3.6.6\n",
            "tzlocal==1.5.1\n",
            "umap-learn==0.3.10\n",
            "uritemplate==3.0.0\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.7.0\n",
            "wasabi==0.4.2\n",
            "wcwidth==0.1.7\n",
            "webencodings==0.5.1\n",
            "Werkzeug==0.16.0\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.11.2\n",
            "xarray==0.11.3\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==1.0.0\n",
            "zipp==0.6.0\n",
            "zmq==0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIXnBwudYLjl",
        "colab_type": "code",
        "outputId": "c7aa5666-7e27-4f27-9614-1e8b1b0ee6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixmPfjVmYYQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "try:\n",
        "    import ujson as json\n",
        "except ImportError:\n",
        "    try:\n",
        "        import simplejson as json\n",
        "    except ImportError:\n",
        "        import json\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pywt\n",
        "import os\n",
        "from PIL import Image\n",
        "# import tensorflow as tf\n",
        "from glob import glob\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.models import Model,load_model,Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout,Flatten, Input\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u0wv_jGZF-L",
        "colab_type": "code",
        "outputId": "37f598f4-3610-448e-fbf7-fe363c85a82a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Pb6W4AZa0d",
        "colab_type": "text"
      },
      "source": [
        "# Data prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRZpm9JxZKEN",
        "colab_type": "code",
        "outputId": "b2cfbefa-5405-49d0-dabb-44711b133a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd drive/'My Drive/lhc_durham'\n",
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/lhc_durham\n",
            "/content/drive/My Drive/lhc_durham\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1MEckdzZ_-1",
        "colab_type": "code",
        "outputId": "8a3a51a5-82d2-4dd0-9dd2-4c63859180d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "img_folder = '/filtered_images'\n",
        "!ls 'filtered_images'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  1  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSJJ8GzogU_i",
        "colab_type": "text"
      },
      "source": [
        "class 0 : DYjets\n",
        "class 1 : TTjets\n",
        "class 2 : Wjets\n",
        "class 3 : ZZjets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK3uFq83Nqp7",
        "colab_type": "text"
      },
      "source": [
        "## Train val size setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd5rd7_ZcoSR",
        "colab_type": "code",
        "outputId": "7d616075-7a95-4555-b86a-c580e8e8a4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "cwd = os.getcwd()\n",
        "img_path = cwd + img_folder\n",
        "\n",
        "train_val_size = 1200\n",
        "\n",
        "df = {}\n",
        "data = []\n",
        "for idx, x in enumerate(os.listdir(img_path)):\n",
        "  if x.isdigit() and idx < 3:\n",
        "    for idx2, pic in enumerate(os.listdir(img_path+'/'+str(x))):\n",
        "      if idx2 < train_val_size:\n",
        "        data.append((img_path+ '/' + x + '/' + pic , x))\n",
        "\n",
        "df = pd.DataFrame(data, columns=['filename', 'class'])\n",
        "df['class'] = df['class'].astype(int)\n",
        "#shuffle\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(df.head())\n",
        "print(len(df))\n",
        "df.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            filename  class\n",
            "0  /content/drive/My Drive/lhc_durham/filtered_im...      2\n",
            "1  /content/drive/My Drive/lhc_durham/filtered_im...      2\n",
            "2  /content/drive/My Drive/lhc_durham/filtered_im...      0\n",
            "3  /content/drive/My Drive/lhc_durham/filtered_im...      0\n",
            "4  /content/drive/My Drive/lhc_durham/filtered_im...      1\n",
            "3600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "filename    object\n",
              "class        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF67c9pOdMix",
        "colab_type": "code",
        "outputId": "d79d750b-29d1-440b-b3e8-502e8d322653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from collections import Counter\n",
        "cnt = Counter(df['class'])\n",
        "cnt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 1200, 1: 1200, 2: 1200})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV8WCnbQhKx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9a40530e-4d74-409a-cebe-c8275ab2521f"
      },
      "source": [
        "# Split into train and validation sets\n",
        "train_percentage = .7\n",
        "val_percentage = 0.15\n",
        "test_percentage = 0.15\n",
        "\n",
        "train_length = int(len(df) * train_percentage)\n",
        "df_train = df[:train_length]\n",
        "\n",
        "val_length = int(len(df) * val_percentage)\n",
        "df_val = df[train_length : train_length+val_length]\n",
        "\n",
        "test_length = int(len(df) * test_percentage)\n",
        "df_test = df[ train_length + val_length : ]\n",
        "\n",
        "# shuffle \n",
        "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
        "df_val = df_val.sample(frac=1).reset_index(drop=True)\n",
        "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df_list = [df_train, df_val, df_test]\n",
        "for df_part in df_list:\n",
        "  print(len(df_part))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2520\n",
            "540\n",
            "540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65hltRStDyg2",
        "colab_type": "text"
      },
      "source": [
        "#### image parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93QOO1_2h5_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reads an image from a file, decodes it into a tensor, and resizes it\n",
        "# to a fixed shape.\n",
        "img_rows, img_cols = 200,200\n",
        "num_classes = len(set(df['class']))\n",
        "batch_size = 256\n",
        "\n",
        "def _parse_function(filename, label):\n",
        "  image_string = tf.io.read_file(filename)\n",
        "  image_decoded = tf.image.decode_jpeg(image_string)\n",
        "  image_resized = tf.image.resize(image_decoded, [img_rows, img_cols])\n",
        "  image_resized = tf.ensure_shape(image_resized ,shape=(img_rows, img_cols,3))\n",
        "  label = tf.one_hot(label, num_classes)\n",
        "  return image_resized, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9GwWMh5iZtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((tf.cast(df_train['filename'].values, tf.string),\n",
        "                                                    tf.cast(df_train['class'].values, tf.int32) ))\n",
        "train_dataset = train_dataset.map(_parse_function)\n",
        "train_dataset = train_dataset.shuffle(5000)\n",
        "train_dataset = train_dataset.repeat()\n",
        "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MfsNRyiicIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_dataset = tf.data.Dataset.from_tensor_slices((tf.cast(df_val['filename'].values, tf.string),\n",
        "                                                    tf.cast(df_val['class'].values, tf.int32) ))\n",
        "valid_dataset = valid_dataset.map(_parse_function)\n",
        "valid_dataset = valid_dataset.shuffle(5000)\n",
        "valid_dataset = valid_dataset.repeat()\n",
        "valid_dataset = valid_dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amK7DVJDPTSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((tf.cast(df_test['filename'].values, tf.string),\n",
        "                                                    tf.cast(df_test['class'].values, tf.int32) ))\n",
        "test_dataset = test_dataset.map(_parse_function)\n",
        "test_dataset = test_dataset.shuffle(5000)\n",
        "test_dataset = test_dataset.repeat()\n",
        "test_dataset = test_dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PsYgoDSieIA",
        "colab_type": "code",
        "outputId": "d2e242cb-bcca-46bd-9402-23c198a45e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 200, 200, 3), (256, 3)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBGgnehQComV",
        "colab_type": "text"
      },
      "source": [
        "# inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmYn28dKigPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6dc5ba10-019a-488f-9afe-f61617cb3c60"
      },
      "source": [
        "base_inception = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(200, 200, 3), pooling=None)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c01m47ajGzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = base_inception.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "#x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# and a logits layer -- let's say we have 3 classes\n",
        "predictions = Dense(3, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yOvde7kjzsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception_model = Model(inputs=base_inception.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K57xbdt9kdm8",
        "colab_type": "code",
        "outputId": "a6c42598-5246-4cc8-c7f3-3aa7449fcc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for layer in base_inception.layers:\n",
        "    layer.trainable = False\n",
        "    print(layer.name, ' Trainable =', layer.trainable)\n",
        "    "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1  Trainable = False\n",
            "conv2d  Trainable = False\n",
            "batch_normalization  Trainable = False\n",
            "activation  Trainable = False\n",
            "conv2d_1  Trainable = False\n",
            "batch_normalization_1  Trainable = False\n",
            "activation_1  Trainable = False\n",
            "conv2d_2  Trainable = False\n",
            "batch_normalization_2  Trainable = False\n",
            "activation_2  Trainable = False\n",
            "max_pooling2d  Trainable = False\n",
            "conv2d_3  Trainable = False\n",
            "batch_normalization_3  Trainable = False\n",
            "activation_3  Trainable = False\n",
            "conv2d_4  Trainable = False\n",
            "batch_normalization_4  Trainable = False\n",
            "activation_4  Trainable = False\n",
            "max_pooling2d_1  Trainable = False\n",
            "conv2d_8  Trainable = False\n",
            "batch_normalization_8  Trainable = False\n",
            "activation_8  Trainable = False\n",
            "conv2d_6  Trainable = False\n",
            "conv2d_9  Trainable = False\n",
            "batch_normalization_6  Trainable = False\n",
            "batch_normalization_9  Trainable = False\n",
            "activation_6  Trainable = False\n",
            "activation_9  Trainable = False\n",
            "average_pooling2d  Trainable = False\n",
            "conv2d_5  Trainable = False\n",
            "conv2d_7  Trainable = False\n",
            "conv2d_10  Trainable = False\n",
            "conv2d_11  Trainable = False\n",
            "batch_normalization_5  Trainable = False\n",
            "batch_normalization_7  Trainable = False\n",
            "batch_normalization_10  Trainable = False\n",
            "batch_normalization_11  Trainable = False\n",
            "activation_5  Trainable = False\n",
            "activation_7  Trainable = False\n",
            "activation_10  Trainable = False\n",
            "activation_11  Trainable = False\n",
            "mixed0  Trainable = False\n",
            "conv2d_15  Trainable = False\n",
            "batch_normalization_15  Trainable = False\n",
            "activation_15  Trainable = False\n",
            "conv2d_13  Trainable = False\n",
            "conv2d_16  Trainable = False\n",
            "batch_normalization_13  Trainable = False\n",
            "batch_normalization_16  Trainable = False\n",
            "activation_13  Trainable = False\n",
            "activation_16  Trainable = False\n",
            "average_pooling2d_1  Trainable = False\n",
            "conv2d_12  Trainable = False\n",
            "conv2d_14  Trainable = False\n",
            "conv2d_17  Trainable = False\n",
            "conv2d_18  Trainable = False\n",
            "batch_normalization_12  Trainable = False\n",
            "batch_normalization_14  Trainable = False\n",
            "batch_normalization_17  Trainable = False\n",
            "batch_normalization_18  Trainable = False\n",
            "activation_12  Trainable = False\n",
            "activation_14  Trainable = False\n",
            "activation_17  Trainable = False\n",
            "activation_18  Trainable = False\n",
            "mixed1  Trainable = False\n",
            "conv2d_22  Trainable = False\n",
            "batch_normalization_22  Trainable = False\n",
            "activation_22  Trainable = False\n",
            "conv2d_20  Trainable = False\n",
            "conv2d_23  Trainable = False\n",
            "batch_normalization_20  Trainable = False\n",
            "batch_normalization_23  Trainable = False\n",
            "activation_20  Trainable = False\n",
            "activation_23  Trainable = False\n",
            "average_pooling2d_2  Trainable = False\n",
            "conv2d_19  Trainable = False\n",
            "conv2d_21  Trainable = False\n",
            "conv2d_24  Trainable = False\n",
            "conv2d_25  Trainable = False\n",
            "batch_normalization_19  Trainable = False\n",
            "batch_normalization_21  Trainable = False\n",
            "batch_normalization_24  Trainable = False\n",
            "batch_normalization_25  Trainable = False\n",
            "activation_19  Trainable = False\n",
            "activation_21  Trainable = False\n",
            "activation_24  Trainable = False\n",
            "activation_25  Trainable = False\n",
            "mixed2  Trainable = False\n",
            "conv2d_27  Trainable = False\n",
            "batch_normalization_27  Trainable = False\n",
            "activation_27  Trainable = False\n",
            "conv2d_28  Trainable = False\n",
            "batch_normalization_28  Trainable = False\n",
            "activation_28  Trainable = False\n",
            "conv2d_26  Trainable = False\n",
            "conv2d_29  Trainable = False\n",
            "batch_normalization_26  Trainable = False\n",
            "batch_normalization_29  Trainable = False\n",
            "activation_26  Trainable = False\n",
            "activation_29  Trainable = False\n",
            "max_pooling2d_2  Trainable = False\n",
            "mixed3  Trainable = False\n",
            "conv2d_34  Trainable = False\n",
            "batch_normalization_34  Trainable = False\n",
            "activation_34  Trainable = False\n",
            "conv2d_35  Trainable = False\n",
            "batch_normalization_35  Trainable = False\n",
            "activation_35  Trainable = False\n",
            "conv2d_31  Trainable = False\n",
            "conv2d_36  Trainable = False\n",
            "batch_normalization_31  Trainable = False\n",
            "batch_normalization_36  Trainable = False\n",
            "activation_31  Trainable = False\n",
            "activation_36  Trainable = False\n",
            "conv2d_32  Trainable = False\n",
            "conv2d_37  Trainable = False\n",
            "batch_normalization_32  Trainable = False\n",
            "batch_normalization_37  Trainable = False\n",
            "activation_32  Trainable = False\n",
            "activation_37  Trainable = False\n",
            "average_pooling2d_3  Trainable = False\n",
            "conv2d_30  Trainable = False\n",
            "conv2d_33  Trainable = False\n",
            "conv2d_38  Trainable = False\n",
            "conv2d_39  Trainable = False\n",
            "batch_normalization_30  Trainable = False\n",
            "batch_normalization_33  Trainable = False\n",
            "batch_normalization_38  Trainable = False\n",
            "batch_normalization_39  Trainable = False\n",
            "activation_30  Trainable = False\n",
            "activation_33  Trainable = False\n",
            "activation_38  Trainable = False\n",
            "activation_39  Trainable = False\n",
            "mixed4  Trainable = False\n",
            "conv2d_44  Trainable = False\n",
            "batch_normalization_44  Trainable = False\n",
            "activation_44  Trainable = False\n",
            "conv2d_45  Trainable = False\n",
            "batch_normalization_45  Trainable = False\n",
            "activation_45  Trainable = False\n",
            "conv2d_41  Trainable = False\n",
            "conv2d_46  Trainable = False\n",
            "batch_normalization_41  Trainable = False\n",
            "batch_normalization_46  Trainable = False\n",
            "activation_41  Trainable = False\n",
            "activation_46  Trainable = False\n",
            "conv2d_42  Trainable = False\n",
            "conv2d_47  Trainable = False\n",
            "batch_normalization_42  Trainable = False\n",
            "batch_normalization_47  Trainable = False\n",
            "activation_42  Trainable = False\n",
            "activation_47  Trainable = False\n",
            "average_pooling2d_4  Trainable = False\n",
            "conv2d_40  Trainable = False\n",
            "conv2d_43  Trainable = False\n",
            "conv2d_48  Trainable = False\n",
            "conv2d_49  Trainable = False\n",
            "batch_normalization_40  Trainable = False\n",
            "batch_normalization_43  Trainable = False\n",
            "batch_normalization_48  Trainable = False\n",
            "batch_normalization_49  Trainable = False\n",
            "activation_40  Trainable = False\n",
            "activation_43  Trainable = False\n",
            "activation_48  Trainable = False\n",
            "activation_49  Trainable = False\n",
            "mixed5  Trainable = False\n",
            "conv2d_54  Trainable = False\n",
            "batch_normalization_54  Trainable = False\n",
            "activation_54  Trainable = False\n",
            "conv2d_55  Trainable = False\n",
            "batch_normalization_55  Trainable = False\n",
            "activation_55  Trainable = False\n",
            "conv2d_51  Trainable = False\n",
            "conv2d_56  Trainable = False\n",
            "batch_normalization_51  Trainable = False\n",
            "batch_normalization_56  Trainable = False\n",
            "activation_51  Trainable = False\n",
            "activation_56  Trainable = False\n",
            "conv2d_52  Trainable = False\n",
            "conv2d_57  Trainable = False\n",
            "batch_normalization_52  Trainable = False\n",
            "batch_normalization_57  Trainable = False\n",
            "activation_52  Trainable = False\n",
            "activation_57  Trainable = False\n",
            "average_pooling2d_5  Trainable = False\n",
            "conv2d_50  Trainable = False\n",
            "conv2d_53  Trainable = False\n",
            "conv2d_58  Trainable = False\n",
            "conv2d_59  Trainable = False\n",
            "batch_normalization_50  Trainable = False\n",
            "batch_normalization_53  Trainable = False\n",
            "batch_normalization_58  Trainable = False\n",
            "batch_normalization_59  Trainable = False\n",
            "activation_50  Trainable = False\n",
            "activation_53  Trainable = False\n",
            "activation_58  Trainable = False\n",
            "activation_59  Trainable = False\n",
            "mixed6  Trainable = False\n",
            "conv2d_64  Trainable = False\n",
            "batch_normalization_64  Trainable = False\n",
            "activation_64  Trainable = False\n",
            "conv2d_65  Trainable = False\n",
            "batch_normalization_65  Trainable = False\n",
            "activation_65  Trainable = False\n",
            "conv2d_61  Trainable = False\n",
            "conv2d_66  Trainable = False\n",
            "batch_normalization_61  Trainable = False\n",
            "batch_normalization_66  Trainable = False\n",
            "activation_61  Trainable = False\n",
            "activation_66  Trainable = False\n",
            "conv2d_62  Trainable = False\n",
            "conv2d_67  Trainable = False\n",
            "batch_normalization_62  Trainable = False\n",
            "batch_normalization_67  Trainable = False\n",
            "activation_62  Trainable = False\n",
            "activation_67  Trainable = False\n",
            "average_pooling2d_6  Trainable = False\n",
            "conv2d_60  Trainable = False\n",
            "conv2d_63  Trainable = False\n",
            "conv2d_68  Trainable = False\n",
            "conv2d_69  Trainable = False\n",
            "batch_normalization_60  Trainable = False\n",
            "batch_normalization_63  Trainable = False\n",
            "batch_normalization_68  Trainable = False\n",
            "batch_normalization_69  Trainable = False\n",
            "activation_60  Trainable = False\n",
            "activation_63  Trainable = False\n",
            "activation_68  Trainable = False\n",
            "activation_69  Trainable = False\n",
            "mixed7  Trainable = False\n",
            "conv2d_72  Trainable = False\n",
            "batch_normalization_72  Trainable = False\n",
            "activation_72  Trainable = False\n",
            "conv2d_73  Trainable = False\n",
            "batch_normalization_73  Trainable = False\n",
            "activation_73  Trainable = False\n",
            "conv2d_70  Trainable = False\n",
            "conv2d_74  Trainable = False\n",
            "batch_normalization_70  Trainable = False\n",
            "batch_normalization_74  Trainable = False\n",
            "activation_70  Trainable = False\n",
            "activation_74  Trainable = False\n",
            "conv2d_71  Trainable = False\n",
            "conv2d_75  Trainable = False\n",
            "batch_normalization_71  Trainable = False\n",
            "batch_normalization_75  Trainable = False\n",
            "activation_71  Trainable = False\n",
            "activation_75  Trainable = False\n",
            "max_pooling2d_3  Trainable = False\n",
            "mixed8  Trainable = False\n",
            "conv2d_80  Trainable = False\n",
            "batch_normalization_80  Trainable = False\n",
            "activation_80  Trainable = False\n",
            "conv2d_77  Trainable = False\n",
            "conv2d_81  Trainable = False\n",
            "batch_normalization_77  Trainable = False\n",
            "batch_normalization_81  Trainable = False\n",
            "activation_77  Trainable = False\n",
            "activation_81  Trainable = False\n",
            "conv2d_78  Trainable = False\n",
            "conv2d_79  Trainable = False\n",
            "conv2d_82  Trainable = False\n",
            "conv2d_83  Trainable = False\n",
            "average_pooling2d_7  Trainable = False\n",
            "conv2d_76  Trainable = False\n",
            "batch_normalization_78  Trainable = False\n",
            "batch_normalization_79  Trainable = False\n",
            "batch_normalization_82  Trainable = False\n",
            "batch_normalization_83  Trainable = False\n",
            "conv2d_84  Trainable = False\n",
            "batch_normalization_76  Trainable = False\n",
            "activation_78  Trainable = False\n",
            "activation_79  Trainable = False\n",
            "activation_82  Trainable = False\n",
            "activation_83  Trainable = False\n",
            "batch_normalization_84  Trainable = False\n",
            "activation_76  Trainable = False\n",
            "mixed9_0  Trainable = False\n",
            "concatenate  Trainable = False\n",
            "activation_84  Trainable = False\n",
            "mixed9  Trainable = False\n",
            "conv2d_89  Trainable = False\n",
            "batch_normalization_89  Trainable = False\n",
            "activation_89  Trainable = False\n",
            "conv2d_86  Trainable = False\n",
            "conv2d_90  Trainable = False\n",
            "batch_normalization_86  Trainable = False\n",
            "batch_normalization_90  Trainable = False\n",
            "activation_86  Trainable = False\n",
            "activation_90  Trainable = False\n",
            "conv2d_87  Trainable = False\n",
            "conv2d_88  Trainable = False\n",
            "conv2d_91  Trainable = False\n",
            "conv2d_92  Trainable = False\n",
            "average_pooling2d_8  Trainable = False\n",
            "conv2d_85  Trainable = False\n",
            "batch_normalization_87  Trainable = False\n",
            "batch_normalization_88  Trainable = False\n",
            "batch_normalization_91  Trainable = False\n",
            "batch_normalization_92  Trainable = False\n",
            "conv2d_93  Trainable = False\n",
            "batch_normalization_85  Trainable = False\n",
            "activation_87  Trainable = False\n",
            "activation_88  Trainable = False\n",
            "activation_91  Trainable = False\n",
            "activation_92  Trainable = False\n",
            "batch_normalization_93  Trainable = False\n",
            "activation_85  Trainable = False\n",
            "mixed9_1  Trainable = False\n",
            "concatenate_1  Trainable = False\n",
            "activation_93  Trainable = False\n",
            "mixed10  Trainable = False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLAWoovdj2Zh",
        "colab_type": "code",
        "outputId": "34d89829-a9b7-4964-ad13-5199a7eaa352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for layer in inception_model.layers:\n",
        "    print(layer.name,' Trainable =',layer.trainable)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1  Trainable = False\n",
            "conv2d  Trainable = False\n",
            "batch_normalization  Trainable = False\n",
            "activation  Trainable = False\n",
            "conv2d_1  Trainable = False\n",
            "batch_normalization_1  Trainable = False\n",
            "activation_1  Trainable = False\n",
            "conv2d_2  Trainable = False\n",
            "batch_normalization_2  Trainable = False\n",
            "activation_2  Trainable = False\n",
            "max_pooling2d  Trainable = False\n",
            "conv2d_3  Trainable = False\n",
            "batch_normalization_3  Trainable = False\n",
            "activation_3  Trainable = False\n",
            "conv2d_4  Trainable = False\n",
            "batch_normalization_4  Trainable = False\n",
            "activation_4  Trainable = False\n",
            "max_pooling2d_1  Trainable = False\n",
            "conv2d_8  Trainable = False\n",
            "batch_normalization_8  Trainable = False\n",
            "activation_8  Trainable = False\n",
            "conv2d_6  Trainable = False\n",
            "conv2d_9  Trainable = False\n",
            "batch_normalization_6  Trainable = False\n",
            "batch_normalization_9  Trainable = False\n",
            "activation_6  Trainable = False\n",
            "activation_9  Trainable = False\n",
            "average_pooling2d  Trainable = False\n",
            "conv2d_5  Trainable = False\n",
            "conv2d_7  Trainable = False\n",
            "conv2d_10  Trainable = False\n",
            "conv2d_11  Trainable = False\n",
            "batch_normalization_5  Trainable = False\n",
            "batch_normalization_7  Trainable = False\n",
            "batch_normalization_10  Trainable = False\n",
            "batch_normalization_11  Trainable = False\n",
            "activation_5  Trainable = False\n",
            "activation_7  Trainable = False\n",
            "activation_10  Trainable = False\n",
            "activation_11  Trainable = False\n",
            "mixed0  Trainable = False\n",
            "conv2d_15  Trainable = False\n",
            "batch_normalization_15  Trainable = False\n",
            "activation_15  Trainable = False\n",
            "conv2d_13  Trainable = False\n",
            "conv2d_16  Trainable = False\n",
            "batch_normalization_13  Trainable = False\n",
            "batch_normalization_16  Trainable = False\n",
            "activation_13  Trainable = False\n",
            "activation_16  Trainable = False\n",
            "average_pooling2d_1  Trainable = False\n",
            "conv2d_12  Trainable = False\n",
            "conv2d_14  Trainable = False\n",
            "conv2d_17  Trainable = False\n",
            "conv2d_18  Trainable = False\n",
            "batch_normalization_12  Trainable = False\n",
            "batch_normalization_14  Trainable = False\n",
            "batch_normalization_17  Trainable = False\n",
            "batch_normalization_18  Trainable = False\n",
            "activation_12  Trainable = False\n",
            "activation_14  Trainable = False\n",
            "activation_17  Trainable = False\n",
            "activation_18  Trainable = False\n",
            "mixed1  Trainable = False\n",
            "conv2d_22  Trainable = False\n",
            "batch_normalization_22  Trainable = False\n",
            "activation_22  Trainable = False\n",
            "conv2d_20  Trainable = False\n",
            "conv2d_23  Trainable = False\n",
            "batch_normalization_20  Trainable = False\n",
            "batch_normalization_23  Trainable = False\n",
            "activation_20  Trainable = False\n",
            "activation_23  Trainable = False\n",
            "average_pooling2d_2  Trainable = False\n",
            "conv2d_19  Trainable = False\n",
            "conv2d_21  Trainable = False\n",
            "conv2d_24  Trainable = False\n",
            "conv2d_25  Trainable = False\n",
            "batch_normalization_19  Trainable = False\n",
            "batch_normalization_21  Trainable = False\n",
            "batch_normalization_24  Trainable = False\n",
            "batch_normalization_25  Trainable = False\n",
            "activation_19  Trainable = False\n",
            "activation_21  Trainable = False\n",
            "activation_24  Trainable = False\n",
            "activation_25  Trainable = False\n",
            "mixed2  Trainable = False\n",
            "conv2d_27  Trainable = False\n",
            "batch_normalization_27  Trainable = False\n",
            "activation_27  Trainable = False\n",
            "conv2d_28  Trainable = False\n",
            "batch_normalization_28  Trainable = False\n",
            "activation_28  Trainable = False\n",
            "conv2d_26  Trainable = False\n",
            "conv2d_29  Trainable = False\n",
            "batch_normalization_26  Trainable = False\n",
            "batch_normalization_29  Trainable = False\n",
            "activation_26  Trainable = False\n",
            "activation_29  Trainable = False\n",
            "max_pooling2d_2  Trainable = False\n",
            "mixed3  Trainable = False\n",
            "conv2d_34  Trainable = False\n",
            "batch_normalization_34  Trainable = False\n",
            "activation_34  Trainable = False\n",
            "conv2d_35  Trainable = False\n",
            "batch_normalization_35  Trainable = False\n",
            "activation_35  Trainable = False\n",
            "conv2d_31  Trainable = False\n",
            "conv2d_36  Trainable = False\n",
            "batch_normalization_31  Trainable = False\n",
            "batch_normalization_36  Trainable = False\n",
            "activation_31  Trainable = False\n",
            "activation_36  Trainable = False\n",
            "conv2d_32  Trainable = False\n",
            "conv2d_37  Trainable = False\n",
            "batch_normalization_32  Trainable = False\n",
            "batch_normalization_37  Trainable = False\n",
            "activation_32  Trainable = False\n",
            "activation_37  Trainable = False\n",
            "average_pooling2d_3  Trainable = False\n",
            "conv2d_30  Trainable = False\n",
            "conv2d_33  Trainable = False\n",
            "conv2d_38  Trainable = False\n",
            "conv2d_39  Trainable = False\n",
            "batch_normalization_30  Trainable = False\n",
            "batch_normalization_33  Trainable = False\n",
            "batch_normalization_38  Trainable = False\n",
            "batch_normalization_39  Trainable = False\n",
            "activation_30  Trainable = False\n",
            "activation_33  Trainable = False\n",
            "activation_38  Trainable = False\n",
            "activation_39  Trainable = False\n",
            "mixed4  Trainable = False\n",
            "conv2d_44  Trainable = False\n",
            "batch_normalization_44  Trainable = False\n",
            "activation_44  Trainable = False\n",
            "conv2d_45  Trainable = False\n",
            "batch_normalization_45  Trainable = False\n",
            "activation_45  Trainable = False\n",
            "conv2d_41  Trainable = False\n",
            "conv2d_46  Trainable = False\n",
            "batch_normalization_41  Trainable = False\n",
            "batch_normalization_46  Trainable = False\n",
            "activation_41  Trainable = False\n",
            "activation_46  Trainable = False\n",
            "conv2d_42  Trainable = False\n",
            "conv2d_47  Trainable = False\n",
            "batch_normalization_42  Trainable = False\n",
            "batch_normalization_47  Trainable = False\n",
            "activation_42  Trainable = False\n",
            "activation_47  Trainable = False\n",
            "average_pooling2d_4  Trainable = False\n",
            "conv2d_40  Trainable = False\n",
            "conv2d_43  Trainable = False\n",
            "conv2d_48  Trainable = False\n",
            "conv2d_49  Trainable = False\n",
            "batch_normalization_40  Trainable = False\n",
            "batch_normalization_43  Trainable = False\n",
            "batch_normalization_48  Trainable = False\n",
            "batch_normalization_49  Trainable = False\n",
            "activation_40  Trainable = False\n",
            "activation_43  Trainable = False\n",
            "activation_48  Trainable = False\n",
            "activation_49  Trainable = False\n",
            "mixed5  Trainable = False\n",
            "conv2d_54  Trainable = False\n",
            "batch_normalization_54  Trainable = False\n",
            "activation_54  Trainable = False\n",
            "conv2d_55  Trainable = False\n",
            "batch_normalization_55  Trainable = False\n",
            "activation_55  Trainable = False\n",
            "conv2d_51  Trainable = False\n",
            "conv2d_56  Trainable = False\n",
            "batch_normalization_51  Trainable = False\n",
            "batch_normalization_56  Trainable = False\n",
            "activation_51  Trainable = False\n",
            "activation_56  Trainable = False\n",
            "conv2d_52  Trainable = False\n",
            "conv2d_57  Trainable = False\n",
            "batch_normalization_52  Trainable = False\n",
            "batch_normalization_57  Trainable = False\n",
            "activation_52  Trainable = False\n",
            "activation_57  Trainable = False\n",
            "average_pooling2d_5  Trainable = False\n",
            "conv2d_50  Trainable = False\n",
            "conv2d_53  Trainable = False\n",
            "conv2d_58  Trainable = False\n",
            "conv2d_59  Trainable = False\n",
            "batch_normalization_50  Trainable = False\n",
            "batch_normalization_53  Trainable = False\n",
            "batch_normalization_58  Trainable = False\n",
            "batch_normalization_59  Trainable = False\n",
            "activation_50  Trainable = False\n",
            "activation_53  Trainable = False\n",
            "activation_58  Trainable = False\n",
            "activation_59  Trainable = False\n",
            "mixed6  Trainable = False\n",
            "conv2d_64  Trainable = False\n",
            "batch_normalization_64  Trainable = False\n",
            "activation_64  Trainable = False\n",
            "conv2d_65  Trainable = False\n",
            "batch_normalization_65  Trainable = False\n",
            "activation_65  Trainable = False\n",
            "conv2d_61  Trainable = False\n",
            "conv2d_66  Trainable = False\n",
            "batch_normalization_61  Trainable = False\n",
            "batch_normalization_66  Trainable = False\n",
            "activation_61  Trainable = False\n",
            "activation_66  Trainable = False\n",
            "conv2d_62  Trainable = False\n",
            "conv2d_67  Trainable = False\n",
            "batch_normalization_62  Trainable = False\n",
            "batch_normalization_67  Trainable = False\n",
            "activation_62  Trainable = False\n",
            "activation_67  Trainable = False\n",
            "average_pooling2d_6  Trainable = False\n",
            "conv2d_60  Trainable = False\n",
            "conv2d_63  Trainable = False\n",
            "conv2d_68  Trainable = False\n",
            "conv2d_69  Trainable = False\n",
            "batch_normalization_60  Trainable = False\n",
            "batch_normalization_63  Trainable = False\n",
            "batch_normalization_68  Trainable = False\n",
            "batch_normalization_69  Trainable = False\n",
            "activation_60  Trainable = False\n",
            "activation_63  Trainable = False\n",
            "activation_68  Trainable = False\n",
            "activation_69  Trainable = False\n",
            "mixed7  Trainable = False\n",
            "conv2d_72  Trainable = False\n",
            "batch_normalization_72  Trainable = False\n",
            "activation_72  Trainable = False\n",
            "conv2d_73  Trainable = False\n",
            "batch_normalization_73  Trainable = False\n",
            "activation_73  Trainable = False\n",
            "conv2d_70  Trainable = False\n",
            "conv2d_74  Trainable = False\n",
            "batch_normalization_70  Trainable = False\n",
            "batch_normalization_74  Trainable = False\n",
            "activation_70  Trainable = False\n",
            "activation_74  Trainable = False\n",
            "conv2d_71  Trainable = False\n",
            "conv2d_75  Trainable = False\n",
            "batch_normalization_71  Trainable = False\n",
            "batch_normalization_75  Trainable = False\n",
            "activation_71  Trainable = False\n",
            "activation_75  Trainable = False\n",
            "max_pooling2d_3  Trainable = False\n",
            "mixed8  Trainable = False\n",
            "conv2d_80  Trainable = False\n",
            "batch_normalization_80  Trainable = False\n",
            "activation_80  Trainable = False\n",
            "conv2d_77  Trainable = False\n",
            "conv2d_81  Trainable = False\n",
            "batch_normalization_77  Trainable = False\n",
            "batch_normalization_81  Trainable = False\n",
            "activation_77  Trainable = False\n",
            "activation_81  Trainable = False\n",
            "conv2d_78  Trainable = False\n",
            "conv2d_79  Trainable = False\n",
            "conv2d_82  Trainable = False\n",
            "conv2d_83  Trainable = False\n",
            "average_pooling2d_7  Trainable = False\n",
            "conv2d_76  Trainable = False\n",
            "batch_normalization_78  Trainable = False\n",
            "batch_normalization_79  Trainable = False\n",
            "batch_normalization_82  Trainable = False\n",
            "batch_normalization_83  Trainable = False\n",
            "conv2d_84  Trainable = False\n",
            "batch_normalization_76  Trainable = False\n",
            "activation_78  Trainable = False\n",
            "activation_79  Trainable = False\n",
            "activation_82  Trainable = False\n",
            "activation_83  Trainable = False\n",
            "batch_normalization_84  Trainable = False\n",
            "activation_76  Trainable = False\n",
            "mixed9_0  Trainable = False\n",
            "concatenate  Trainable = False\n",
            "activation_84  Trainable = False\n",
            "mixed9  Trainable = False\n",
            "conv2d_89  Trainable = False\n",
            "batch_normalization_89  Trainable = False\n",
            "activation_89  Trainable = False\n",
            "conv2d_86  Trainable = False\n",
            "conv2d_90  Trainable = False\n",
            "batch_normalization_86  Trainable = False\n",
            "batch_normalization_90  Trainable = False\n",
            "activation_86  Trainable = False\n",
            "activation_90  Trainable = False\n",
            "conv2d_87  Trainable = False\n",
            "conv2d_88  Trainable = False\n",
            "conv2d_91  Trainable = False\n",
            "conv2d_92  Trainable = False\n",
            "average_pooling2d_8  Trainable = False\n",
            "conv2d_85  Trainable = False\n",
            "batch_normalization_87  Trainable = False\n",
            "batch_normalization_88  Trainable = False\n",
            "batch_normalization_91  Trainable = False\n",
            "batch_normalization_92  Trainable = False\n",
            "conv2d_93  Trainable = False\n",
            "batch_normalization_85  Trainable = False\n",
            "activation_87  Trainable = False\n",
            "activation_88  Trainable = False\n",
            "activation_91  Trainable = False\n",
            "activation_92  Trainable = False\n",
            "batch_normalization_93  Trainable = False\n",
            "activation_85  Trainable = False\n",
            "mixed9_1  Trainable = False\n",
            "concatenate_1  Trainable = False\n",
            "activation_93  Trainable = False\n",
            "mixed10  Trainable = False\n",
            "global_average_pooling2d  Trainable = True\n",
            "dense  Trainable = True\n",
            "dropout  Trainable = True\n",
            "dense_1  Trainable = True\n",
            "dropout_1  Trainable = True\n",
            "dense_2  Trainable = True\n",
            "dropout_2  Trainable = True\n",
            "dense_3  Trainable = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLbZOgbPkay5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#opt = tf.keras.optimizers.Adam(lr=0.001)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=1e-4)\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "inception_model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5QTzooTlgct",
        "colab_type": "code",
        "outputId": "84cf53ec-2820-4f37-ec95-370b88b70c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_steps = int(len(df)/batch_size) #total trains set / batch_size\n",
        "val_steps = int(len(df_val)/batch_size)\n",
        "\n",
        "\n",
        "print('train steps:',train_steps)\n",
        "print('val steps:',val_steps)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train steps: 14\n",
            "val steps: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpEN4e-8lRki",
        "colab_type": "code",
        "outputId": "0bbf5577-a5ff-43d6-f388-f56456fa424a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "### Train the model with validation \n",
        "inception_history = inception_model.fit( train_dataset, steps_per_epoch = train_steps,\n",
        "                   epochs = epochs,\n",
        "                   validation_data = valid_dataset,\n",
        "                   validation_steps = val_steps)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 14 steps, validate for 2 steps\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1209s 86s/step - loss: 1.1718 - accuracy: 0.3624 - val_loss: 15.5247 - val_accuracy: 0.3398\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 9s 678ms/step - loss: 1.0676 - accuracy: 0.4308 - val_loss: 18.6768 - val_accuracy: 0.3535\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 13s 964ms/step - loss: 1.0066 - accuracy: 0.4914 - val_loss: 23.5423 - val_accuracy: 0.3301\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 9s 668ms/step - loss: 0.9283 - accuracy: 0.5544 - val_loss: 25.3122 - val_accuracy: 0.3242\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 14s 972ms/step - loss: 0.8825 - accuracy: 0.5801 - val_loss: 37.0807 - val_accuracy: 0.3379\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 9s 664ms/step - loss: 0.8256 - accuracy: 0.6116 - val_loss: 38.1529 - val_accuracy: 0.3320\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 9s 668ms/step - loss: 0.7803 - accuracy: 0.6331 - val_loss: 26.4128 - val_accuracy: 0.3398\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.7557 - accuracy: 0.6627 - val_loss: 40.1109 - val_accuracy: 0.3262\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 10s 681ms/step - loss: 0.7341 - accuracy: 0.6574 - val_loss: 50.7852 - val_accuracy: 0.3262\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.6999 - accuracy: 0.6855 - val_loss: 70.3227 - val_accuracy: 0.3320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_wj1elhlT5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception_model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in inception_model.layers:\n",
        "    if layer.name == 'conv2d_181':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4473X2c4mxE",
        "colab_type": "code",
        "outputId": "85dba528-0543-4c0a-876c-d075f6e64700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for layer in inception_model.layers:\n",
        "    print(layer.name,' Trainable =',layer.trainable)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_3  Trainable = False\n",
            "conv2d  Trainable = False\n",
            "batch_normalization  Trainable = False\n",
            "activation  Trainable = False\n",
            "conv2d_1  Trainable = False\n",
            "batch_normalization_1  Trainable = False\n",
            "activation_1  Trainable = False\n",
            "conv2d_2  Trainable = False\n",
            "batch_normalization_2  Trainable = False\n",
            "activation_2  Trainable = False\n",
            "max_pooling2d  Trainable = False\n",
            "conv2d_3  Trainable = False\n",
            "batch_normalization_3  Trainable = False\n",
            "activation_3  Trainable = False\n",
            "conv2d_4  Trainable = False\n",
            "batch_normalization_4  Trainable = False\n",
            "activation_4  Trainable = False\n",
            "max_pooling2d_1  Trainable = False\n",
            "conv2d_8  Trainable = False\n",
            "batch_normalization_8  Trainable = False\n",
            "activation_8  Trainable = False\n",
            "conv2d_6  Trainable = False\n",
            "conv2d_9  Trainable = False\n",
            "batch_normalization_6  Trainable = False\n",
            "batch_normalization_9  Trainable = False\n",
            "activation_6  Trainable = False\n",
            "activation_9  Trainable = False\n",
            "average_pooling2d  Trainable = False\n",
            "conv2d_5  Trainable = False\n",
            "conv2d_7  Trainable = False\n",
            "conv2d_10  Trainable = False\n",
            "conv2d_11  Trainable = False\n",
            "batch_normalization_5  Trainable = False\n",
            "batch_normalization_7  Trainable = False\n",
            "batch_normalization_10  Trainable = False\n",
            "batch_normalization_11  Trainable = False\n",
            "activation_5  Trainable = False\n",
            "activation_7  Trainable = False\n",
            "activation_10  Trainable = False\n",
            "activation_11  Trainable = False\n",
            "mixed0  Trainable = False\n",
            "conv2d_15  Trainable = False\n",
            "batch_normalization_15  Trainable = False\n",
            "activation_15  Trainable = False\n",
            "conv2d_13  Trainable = False\n",
            "conv2d_16  Trainable = False\n",
            "batch_normalization_13  Trainable = False\n",
            "batch_normalization_16  Trainable = False\n",
            "activation_13  Trainable = False\n",
            "activation_16  Trainable = False\n",
            "average_pooling2d_1  Trainable = False\n",
            "conv2d_12  Trainable = False\n",
            "conv2d_14  Trainable = False\n",
            "conv2d_17  Trainable = False\n",
            "conv2d_18  Trainable = False\n",
            "batch_normalization_12  Trainable = False\n",
            "batch_normalization_14  Trainable = False\n",
            "batch_normalization_17  Trainable = False\n",
            "batch_normalization_18  Trainable = False\n",
            "activation_12  Trainable = False\n",
            "activation_14  Trainable = False\n",
            "activation_17  Trainable = False\n",
            "activation_18  Trainable = False\n",
            "mixed1  Trainable = False\n",
            "conv2d_22  Trainable = False\n",
            "batch_normalization_22  Trainable = False\n",
            "activation_22  Trainable = False\n",
            "conv2d_20  Trainable = False\n",
            "conv2d_23  Trainable = False\n",
            "batch_normalization_20  Trainable = False\n",
            "batch_normalization_23  Trainable = False\n",
            "activation_20  Trainable = False\n",
            "activation_23  Trainable = False\n",
            "average_pooling2d_2  Trainable = False\n",
            "conv2d_19  Trainable = False\n",
            "conv2d_21  Trainable = False\n",
            "conv2d_24  Trainable = False\n",
            "conv2d_25  Trainable = False\n",
            "batch_normalization_19  Trainable = False\n",
            "batch_normalization_21  Trainable = False\n",
            "batch_normalization_24  Trainable = False\n",
            "batch_normalization_25  Trainable = False\n",
            "activation_19  Trainable = False\n",
            "activation_21  Trainable = False\n",
            "activation_24  Trainable = False\n",
            "activation_25  Trainable = False\n",
            "mixed2  Trainable = False\n",
            "conv2d_27  Trainable = False\n",
            "batch_normalization_27  Trainable = False\n",
            "activation_27  Trainable = False\n",
            "conv2d_28  Trainable = False\n",
            "batch_normalization_28  Trainable = False\n",
            "activation_28  Trainable = False\n",
            "conv2d_26  Trainable = False\n",
            "conv2d_29  Trainable = False\n",
            "batch_normalization_26  Trainable = False\n",
            "batch_normalization_29  Trainable = False\n",
            "activation_26  Trainable = False\n",
            "activation_29  Trainable = False\n",
            "max_pooling2d_2  Trainable = False\n",
            "mixed3  Trainable = False\n",
            "conv2d_34  Trainable = False\n",
            "batch_normalization_34  Trainable = False\n",
            "activation_34  Trainable = False\n",
            "conv2d_35  Trainable = False\n",
            "batch_normalization_35  Trainable = False\n",
            "activation_35  Trainable = False\n",
            "conv2d_31  Trainable = False\n",
            "conv2d_36  Trainable = False\n",
            "batch_normalization_31  Trainable = False\n",
            "batch_normalization_36  Trainable = False\n",
            "activation_31  Trainable = False\n",
            "activation_36  Trainable = False\n",
            "conv2d_32  Trainable = False\n",
            "conv2d_37  Trainable = False\n",
            "batch_normalization_32  Trainable = False\n",
            "batch_normalization_37  Trainable = False\n",
            "activation_32  Trainable = False\n",
            "activation_37  Trainable = False\n",
            "average_pooling2d_3  Trainable = False\n",
            "conv2d_30  Trainable = False\n",
            "conv2d_33  Trainable = False\n",
            "conv2d_38  Trainable = False\n",
            "conv2d_39  Trainable = False\n",
            "batch_normalization_30  Trainable = False\n",
            "batch_normalization_33  Trainable = False\n",
            "batch_normalization_38  Trainable = False\n",
            "batch_normalization_39  Trainable = False\n",
            "activation_30  Trainable = False\n",
            "activation_33  Trainable = False\n",
            "activation_38  Trainable = False\n",
            "activation_39  Trainable = False\n",
            "mixed4  Trainable = False\n",
            "conv2d_44  Trainable = False\n",
            "batch_normalization_44  Trainable = False\n",
            "activation_44  Trainable = False\n",
            "conv2d_45  Trainable = False\n",
            "batch_normalization_45  Trainable = False\n",
            "activation_45  Trainable = False\n",
            "conv2d_41  Trainable = False\n",
            "conv2d_46  Trainable = False\n",
            "batch_normalization_41  Trainable = False\n",
            "batch_normalization_46  Trainable = False\n",
            "activation_41  Trainable = False\n",
            "activation_46  Trainable = False\n",
            "conv2d_42  Trainable = False\n",
            "conv2d_47  Trainable = False\n",
            "batch_normalization_42  Trainable = False\n",
            "batch_normalization_47  Trainable = False\n",
            "activation_42  Trainable = False\n",
            "activation_47  Trainable = False\n",
            "average_pooling2d_4  Trainable = False\n",
            "conv2d_40  Trainable = False\n",
            "conv2d_43  Trainable = False\n",
            "conv2d_48  Trainable = False\n",
            "conv2d_49  Trainable = False\n",
            "batch_normalization_40  Trainable = False\n",
            "batch_normalization_43  Trainable = False\n",
            "batch_normalization_48  Trainable = False\n",
            "batch_normalization_49  Trainable = False\n",
            "activation_40  Trainable = False\n",
            "activation_43  Trainable = False\n",
            "activation_48  Trainable = False\n",
            "activation_49  Trainable = False\n",
            "mixed5  Trainable = False\n",
            "conv2d_54  Trainable = False\n",
            "batch_normalization_54  Trainable = False\n",
            "activation_54  Trainable = False\n",
            "conv2d_55  Trainable = False\n",
            "batch_normalization_55  Trainable = False\n",
            "activation_55  Trainable = False\n",
            "conv2d_51  Trainable = False\n",
            "conv2d_56  Trainable = False\n",
            "batch_normalization_51  Trainable = False\n",
            "batch_normalization_56  Trainable = False\n",
            "activation_51  Trainable = False\n",
            "activation_56  Trainable = False\n",
            "conv2d_52  Trainable = False\n",
            "conv2d_57  Trainable = False\n",
            "batch_normalization_52  Trainable = False\n",
            "batch_normalization_57  Trainable = False\n",
            "activation_52  Trainable = False\n",
            "activation_57  Trainable = False\n",
            "average_pooling2d_5  Trainable = False\n",
            "conv2d_50  Trainable = False\n",
            "conv2d_53  Trainable = False\n",
            "conv2d_58  Trainable = False\n",
            "conv2d_59  Trainable = False\n",
            "batch_normalization_50  Trainable = False\n",
            "batch_normalization_53  Trainable = False\n",
            "batch_normalization_58  Trainable = False\n",
            "batch_normalization_59  Trainable = False\n",
            "activation_50  Trainable = False\n",
            "activation_53  Trainable = False\n",
            "activation_58  Trainable = False\n",
            "activation_59  Trainable = False\n",
            "mixed6  Trainable = False\n",
            "conv2d_64  Trainable = False\n",
            "batch_normalization_64  Trainable = False\n",
            "activation_64  Trainable = False\n",
            "conv2d_65  Trainable = False\n",
            "batch_normalization_65  Trainable = False\n",
            "activation_65  Trainable = False\n",
            "conv2d_61  Trainable = False\n",
            "conv2d_66  Trainable = False\n",
            "batch_normalization_61  Trainable = False\n",
            "batch_normalization_66  Trainable = False\n",
            "activation_61  Trainable = False\n",
            "activation_66  Trainable = False\n",
            "conv2d_62  Trainable = False\n",
            "conv2d_67  Trainable = False\n",
            "batch_normalization_62  Trainable = False\n",
            "batch_normalization_67  Trainable = False\n",
            "activation_62  Trainable = False\n",
            "activation_67  Trainable = False\n",
            "average_pooling2d_6  Trainable = False\n",
            "conv2d_60  Trainable = False\n",
            "conv2d_63  Trainable = False\n",
            "conv2d_68  Trainable = False\n",
            "conv2d_69  Trainable = False\n",
            "batch_normalization_60  Trainable = False\n",
            "batch_normalization_63  Trainable = False\n",
            "batch_normalization_68  Trainable = False\n",
            "batch_normalization_69  Trainable = False\n",
            "activation_60  Trainable = False\n",
            "activation_63  Trainable = False\n",
            "activation_68  Trainable = False\n",
            "activation_69  Trainable = False\n",
            "mixed7  Trainable = False\n",
            "conv2d_72  Trainable = False\n",
            "batch_normalization_72  Trainable = False\n",
            "activation_72  Trainable = False\n",
            "conv2d_73  Trainable = False\n",
            "batch_normalization_73  Trainable = False\n",
            "activation_73  Trainable = False\n",
            "conv2d_70  Trainable = False\n",
            "conv2d_74  Trainable = False\n",
            "batch_normalization_70  Trainable = False\n",
            "batch_normalization_74  Trainable = False\n",
            "activation_70  Trainable = False\n",
            "activation_74  Trainable = False\n",
            "conv2d_71  Trainable = False\n",
            "conv2d_75  Trainable = False\n",
            "batch_normalization_71  Trainable = False\n",
            "batch_normalization_75  Trainable = False\n",
            "activation_71  Trainable = False\n",
            "activation_75  Trainable = False\n",
            "max_pooling2d_3  Trainable = False\n",
            "mixed8  Trainable = False\n",
            "conv2d_80  Trainable = False\n",
            "batch_normalization_80  Trainable = False\n",
            "activation_80  Trainable = False\n",
            "conv2d_77  Trainable = False\n",
            "conv2d_81  Trainable = False\n",
            "batch_normalization_77  Trainable = False\n",
            "batch_normalization_81  Trainable = False\n",
            "activation_77  Trainable = False\n",
            "activation_81  Trainable = False\n",
            "conv2d_78  Trainable = False\n",
            "conv2d_79  Trainable = False\n",
            "conv2d_82  Trainable = False\n",
            "conv2d_83  Trainable = False\n",
            "average_pooling2d_7  Trainable = False\n",
            "conv2d_76  Trainable = False\n",
            "batch_normalization_78  Trainable = False\n",
            "batch_normalization_79  Trainable = False\n",
            "batch_normalization_82  Trainable = False\n",
            "batch_normalization_83  Trainable = False\n",
            "conv2d_84  Trainable = False\n",
            "batch_normalization_76  Trainable = False\n",
            "activation_78  Trainable = False\n",
            "activation_79  Trainable = False\n",
            "activation_82  Trainable = False\n",
            "activation_83  Trainable = False\n",
            "batch_normalization_84  Trainable = False\n",
            "activation_76  Trainable = False\n",
            "mixed9_0  Trainable = False\n",
            "concatenate  Trainable = False\n",
            "activation_84  Trainable = False\n",
            "mixed9  Trainable = False\n",
            "conv2d_89  Trainable = False\n",
            "batch_normalization_89  Trainable = False\n",
            "activation_89  Trainable = False\n",
            "conv2d_86  Trainable = False\n",
            "conv2d_90  Trainable = False\n",
            "batch_normalization_86  Trainable = False\n",
            "batch_normalization_90  Trainable = False\n",
            "activation_86  Trainable = False\n",
            "activation_90  Trainable = False\n",
            "conv2d_87  Trainable = False\n",
            "conv2d_88  Trainable = False\n",
            "conv2d_91  Trainable = False\n",
            "conv2d_92  Trainable = False\n",
            "average_pooling2d_8  Trainable = False\n",
            "conv2d_85  Trainable = False\n",
            "batch_normalization_87  Trainable = False\n",
            "batch_normalization_88  Trainable = False\n",
            "batch_normalization_91  Trainable = False\n",
            "batch_normalization_92  Trainable = False\n",
            "conv2d_93  Trainable = False\n",
            "batch_normalization_85  Trainable = False\n",
            "activation_87  Trainable = False\n",
            "activation_88  Trainable = False\n",
            "activation_91  Trainable = False\n",
            "activation_92  Trainable = False\n",
            "batch_normalization_93  Trainable = False\n",
            "activation_85  Trainable = False\n",
            "mixed9_1  Trainable = False\n",
            "concatenate_1  Trainable = False\n",
            "activation_93  Trainable = False\n",
            "mixed10  Trainable = False\n",
            "global_average_pooling2d_2  Trainable = False\n",
            "dense_4  Trainable = False\n",
            "dropout_2  Trainable = False\n",
            "dense_5  Trainable = False\n",
            "dropout_3  Trainable = False\n",
            "dense_6  Trainable = False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwivZWYZ4p2p",
        "colab_type": "code",
        "outputId": "6b39b33b-ca5e-46fc-b6ec-825b8a8889ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "\t\n",
        "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=50)\n",
        "\n",
        "# Train the model with validation \n",
        "tuned_inception_history = inception_model.fit( train_dataset, steps_per_epoch = train_steps,\n",
        "                   epochs = epochs,\n",
        "                   validation_data = valid_dataset,\n",
        "                   validation_steps = val_steps,\n",
        "                   callbacks=[es])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 17 steps, validate for 2 steps\n",
            "Epoch 1/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3618 - accuracy: 0.8463 - val_loss: 37.8424 - val_accuracy: 0.3184\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 12s 722ms/step - loss: 0.3589 - accuracy: 0.8421 - val_loss: 49.6048 - val_accuracy: 0.3320\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3792 - accuracy: 0.8304 - val_loss: 59.1348 - val_accuracy: 0.3457\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 12s 725ms/step - loss: 0.3308 - accuracy: 0.8591 - val_loss: 57.4081 - val_accuracy: 0.3301\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 12s 716ms/step - loss: 0.3058 - accuracy: 0.8697 - val_loss: 110.4535 - val_accuracy: 0.3516\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2873 - accuracy: 0.8780 - val_loss: 84.0913 - val_accuracy: 0.3477\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 12s 715ms/step - loss: 0.2744 - accuracy: 0.8860 - val_loss: 63.6652 - val_accuracy: 0.3516\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2700 - accuracy: 0.8897 - val_loss: 119.9577 - val_accuracy: 0.3594\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 12s 717ms/step - loss: 0.2619 - accuracy: 0.8941 - val_loss: 156.8447 - val_accuracy: 0.3379\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 12s 723ms/step - loss: 0.2629 - accuracy: 0.8927 - val_loss: 68.9920 - val_accuracy: 0.3027\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2470 - accuracy: 0.9017 - val_loss: 78.1851 - val_accuracy: 0.3262\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 12s 721ms/step - loss: 0.2214 - accuracy: 0.9072 - val_loss: 51.5826 - val_accuracy: 0.3066\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 13s 756ms/step - loss: 0.2134 - accuracy: 0.9187 - val_loss: 63.6360 - val_accuracy: 0.3262\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1923 - accuracy: 0.9246 - val_loss: 106.9960 - val_accuracy: 0.3594\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 12s 719ms/step - loss: 0.2071 - accuracy: 0.9173 - val_loss: 50.3701 - val_accuracy: 0.3535\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1951 - accuracy: 0.9203 - val_loss: 72.4279 - val_accuracy: 0.3086\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 12s 710ms/step - loss: 0.1853 - accuracy: 0.9246 - val_loss: 63.4357 - val_accuracy: 0.3730\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 12s 711ms/step - loss: 0.1874 - accuracy: 0.9251 - val_loss: 91.2361 - val_accuracy: 0.3203\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1812 - accuracy: 0.9299 - val_loss: 91.0556 - val_accuracy: 0.3359\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 12s 708ms/step - loss: 0.1756 - accuracy: 0.9320 - val_loss: 115.1484 - val_accuracy: 0.3105\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 19s 1s/step - loss: 0.2218 - accuracy: 0.9108 - val_loss: 68.5948 - val_accuracy: 0.2852\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 12s 713ms/step - loss: 0.2095 - accuracy: 0.9092 - val_loss: 80.7701 - val_accuracy: 0.3477\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 12s 710ms/step - loss: 0.2308 - accuracy: 0.9120 - val_loss: 117.6952 - val_accuracy: 0.3340\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2244 - accuracy: 0.9088 - val_loss: 107.7353 - val_accuracy: 0.3301\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 12s 708ms/step - loss: 0.2291 - accuracy: 0.9074 - val_loss: 73.4982 - val_accuracy: 0.3008\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 12s 732ms/step - loss: 0.2374 - accuracy: 0.9060 - val_loss: 87.0000 - val_accuracy: 0.3301\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2045 - accuracy: 0.9198 - val_loss: 109.5618 - val_accuracy: 0.3379\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 12s 718ms/step - loss: 0.2017 - accuracy: 0.9191 - val_loss: 70.5089 - val_accuracy: 0.3496\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1889 - accuracy: 0.9244 - val_loss: 59.7646 - val_accuracy: 0.3477\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 12s 707ms/step - loss: 0.1932 - accuracy: 0.9233 - val_loss: 80.2912 - val_accuracy: 0.4082\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 12s 712ms/step - loss: 0.1654 - accuracy: 0.9373 - val_loss: 99.0749 - val_accuracy: 0.3301\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1778 - accuracy: 0.9283 - val_loss: 212.9857 - val_accuracy: 0.3262\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 12s 715ms/step - loss: 0.1790 - accuracy: 0.9269 - val_loss: 77.7974 - val_accuracy: 0.3379\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 13s 741ms/step - loss: 0.1592 - accuracy: 0.9366 - val_loss: 98.1570 - val_accuracy: 0.3027\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1392 - accuracy: 0.9435 - val_loss: 163.6089 - val_accuracy: 0.3438\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 12s 711ms/step - loss: 0.1404 - accuracy: 0.9453 - val_loss: 81.1555 - val_accuracy: 0.3535\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1527 - accuracy: 0.9407 - val_loss: 154.7835 - val_accuracy: 0.3379\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 12s 721ms/step - loss: 0.1745 - accuracy: 0.9343 - val_loss: 92.8442 - val_accuracy: 0.2969\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 12s 714ms/step - loss: 0.1447 - accuracy: 0.9426 - val_loss: 101.5163 - val_accuracy: 0.3672\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1549 - accuracy: 0.9361 - val_loss: 112.8996 - val_accuracy: 0.2988\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 12s 718ms/step - loss: 0.1483 - accuracy: 0.9444 - val_loss: 152.9544 - val_accuracy: 0.3203\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1446 - accuracy: 0.9409 - val_loss: 180.4522 - val_accuracy: 0.2734\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 12s 721ms/step - loss: 0.1478 - accuracy: 0.9453 - val_loss: 131.9274 - val_accuracy: 0.2969\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 12s 715ms/step - loss: 0.1505 - accuracy: 0.9407 - val_loss: 136.6123 - val_accuracy: 0.3203\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1271 - accuracy: 0.9550 - val_loss: 264.3119 - val_accuracy: 0.3125\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 12s 714ms/step - loss: 0.1171 - accuracy: 0.9554 - val_loss: 204.7972 - val_accuracy: 0.2852\n",
            "Epoch 47/50\n",
            " 2/17 [==>...........................] - ETA: 4s - loss: 0.1609 - accuracy: 0.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-604cf5f7be2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                    callbacks=[es])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    807\u001b[0m   \"\"\"\n\u001b[1;32m    808\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrepresentable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \"\"\"\n\u001b[0;32m--> 938\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5Nj03hx5DQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YofamALVCrtt",
        "colab_type": "text"
      },
      "source": [
        "# vgg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzO1JHNJ1D6I",
        "colab_type": "text"
      },
      "source": [
        "## basic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTe9kVl2CuIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1fae5dae-94c8-4a20-e4c9-82c14aec240c"
      },
      "source": [
        "base_vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3),pooling=None)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUTuVUnlC2-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = base_vgg.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# and a logits layer -- let's say we have 3 classes\n",
        "predictions = Dense(3, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm-iZAuZC7sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the model we will train\n",
        "base_vgg_model = Model(inputs=base_vgg.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f99YWWgxC99k",
        "colab_type": "code",
        "outputId": "79ca8a77-90c4-41f2-bc09-39a21d49b62a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "for layer in base_vgg.layers:\n",
        "    print(layer.name)\n",
        "    layer.trainable = False"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_2\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2P0-ZTaDAPW",
        "colab_type": "code",
        "outputId": "6e9dbea8-6ea4-472e-d61c-3cae13482888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "for layer in base_vgg_model.layers:\n",
        "    print(layer.name,' Trainable =',layer.trainable)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_2  Trainable = False\n",
            "block1_conv1  Trainable = False\n",
            "block1_conv2  Trainable = False\n",
            "block1_pool  Trainable = False\n",
            "block2_conv1  Trainable = False\n",
            "block2_conv2  Trainable = False\n",
            "block2_pool  Trainable = False\n",
            "block3_conv1  Trainable = False\n",
            "block3_conv2  Trainable = False\n",
            "block3_conv3  Trainable = False\n",
            "block3_pool  Trainable = False\n",
            "block4_conv1  Trainable = False\n",
            "block4_conv2  Trainable = False\n",
            "block4_conv3  Trainable = False\n",
            "block4_pool  Trainable = False\n",
            "block5_conv1  Trainable = False\n",
            "block5_conv2  Trainable = False\n",
            "block5_conv3  Trainable = False\n",
            "block5_pool  Trainable = False\n",
            "global_average_pooling2d_1  Trainable = True\n",
            "dense_4  Trainable = True\n",
            "dropout_3  Trainable = True\n",
            "dense_5  Trainable = True\n",
            "dropout_4  Trainable = True\n",
            "dense_6  Trainable = True\n",
            "dropout_5  Trainable = True\n",
            "dense_7  Trainable = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOYp6zEBDDF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.RMSprop(lr=1e-4)\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "base_vgg_model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZilESfkQDI0b",
        "colab_type": "code",
        "outputId": "e5249c7b-1dec-4566-b280-3a0ec8ae4fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_steps = int(len(df)/batch_size) #total trains set / batch_size\n",
        "val_steps = int(len(df_val)/batch_size)\n",
        "#epochs = 1\n",
        "\n",
        "print('train steps:',train_steps)\n",
        "print('val steps:',val_steps)\n",
        "epochs = 50\n",
        "\n",
        "### Train the model with validation \n",
        "vgg_history = base_vgg_model.fit( train_dataset, steps_per_epoch = train_steps,\n",
        "                   epochs = epochs,\n",
        "                   validation_data = valid_dataset,\n",
        "                   validation_steps = val_steps)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train steps: 14\n",
            "val steps: 2\n",
            "Train for 14 steps, validate for 2 steps\n",
            "Epoch 1/200\n",
            "14/14 [==============================] - 21s 2s/step - loss: 1.5742 - accuracy: 0.4445 - val_loss: 0.6975 - val_accuracy: 0.6387\n",
            "Epoch 2/200\n",
            "14/14 [==============================] - 13s 963ms/step - loss: 1.0931 - accuracy: 0.5586 - val_loss: 0.6370 - val_accuracy: 0.7129\n",
            "Epoch 3/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.9563 - accuracy: 0.5968 - val_loss: 0.6120 - val_accuracy: 0.7148\n",
            "Epoch 4/200\n",
            "14/14 [==============================] - 13s 952ms/step - loss: 0.8370 - accuracy: 0.6300 - val_loss: 0.6110 - val_accuracy: 0.7383\n",
            "Epoch 5/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.7937 - accuracy: 0.6431 - val_loss: 0.6275 - val_accuracy: 0.7266\n",
            "Epoch 6/200\n",
            "14/14 [==============================] - 13s 949ms/step - loss: 0.7272 - accuracy: 0.6694 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
            "Epoch 7/200\n",
            "14/14 [==============================] - 14s 968ms/step - loss: 0.7021 - accuracy: 0.6716 - val_loss: 0.5991 - val_accuracy: 0.7441\n",
            "Epoch 8/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.6657 - accuracy: 0.6922 - val_loss: 0.6115 - val_accuracy: 0.7383\n",
            "Epoch 9/200\n",
            "14/14 [==============================] - 13s 957ms/step - loss: 0.6755 - accuracy: 0.6861 - val_loss: 0.6001 - val_accuracy: 0.7422\n",
            "Epoch 10/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.6457 - accuracy: 0.7059 - val_loss: 0.6053 - val_accuracy: 0.7285\n",
            "Epoch 11/200\n",
            "14/14 [==============================] - 13s 946ms/step - loss: 0.6374 - accuracy: 0.7015 - val_loss: 0.5918 - val_accuracy: 0.7461\n",
            "Epoch 12/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.6291 - accuracy: 0.7132 - val_loss: 0.5872 - val_accuracy: 0.7422\n",
            "Epoch 13/200\n",
            "14/14 [==============================] - 14s 1000ms/step - loss: 0.5880 - accuracy: 0.7210 - val_loss: 0.5941 - val_accuracy: 0.7441\n",
            "Epoch 14/200\n",
            "14/14 [==============================] - 13s 954ms/step - loss: 0.5935 - accuracy: 0.7227 - val_loss: 0.5671 - val_accuracy: 0.7617\n",
            "Epoch 15/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.6004 - accuracy: 0.7266 - val_loss: 0.5878 - val_accuracy: 0.7520\n",
            "Epoch 16/200\n",
            "14/14 [==============================] - 13s 954ms/step - loss: 0.5734 - accuracy: 0.7419 - val_loss: 0.5938 - val_accuracy: 0.7559\n",
            "Epoch 17/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.5700 - accuracy: 0.7391 - val_loss: 0.5664 - val_accuracy: 0.7656\n",
            "Epoch 18/200\n",
            "14/14 [==============================] - 13s 957ms/step - loss: 0.5698 - accuracy: 0.7444 - val_loss: 0.5793 - val_accuracy: 0.7656\n",
            "Epoch 19/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.5573 - accuracy: 0.7478 - val_loss: 0.5758 - val_accuracy: 0.7676\n",
            "Epoch 20/200\n",
            "14/14 [==============================] - 13s 952ms/step - loss: 0.5525 - accuracy: 0.7573 - val_loss: 0.5587 - val_accuracy: 0.7832\n",
            "Epoch 21/200\n",
            "14/14 [==============================] - 13s 964ms/step - loss: 0.5444 - accuracy: 0.7575 - val_loss: 0.5764 - val_accuracy: 0.7676\n",
            "Epoch 22/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.5518 - accuracy: 0.7609 - val_loss: 0.5651 - val_accuracy: 0.7773\n",
            "Epoch 23/200\n",
            "14/14 [==============================] - 13s 959ms/step - loss: 0.5447 - accuracy: 0.7623 - val_loss: 0.5616 - val_accuracy: 0.7793\n",
            "Epoch 24/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.5365 - accuracy: 0.7561 - val_loss: 0.5729 - val_accuracy: 0.7598\n",
            "Epoch 25/200\n",
            "14/14 [==============================] - 13s 953ms/step - loss: 0.5349 - accuracy: 0.7628 - val_loss: 0.5748 - val_accuracy: 0.7773\n",
            "Epoch 26/200\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.5344 - accuracy: 0.7701 - val_loss: 0.5649 - val_accuracy: 0.7754\n",
            "Epoch 27/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.5104 - accuracy: 0.7720 - val_loss: 0.5573 - val_accuracy: 0.7754\n",
            "Epoch 28/200\n",
            "14/14 [==============================] - 14s 974ms/step - loss: 0.5126 - accuracy: 0.7782 - val_loss: 0.5594 - val_accuracy: 0.7676\n",
            "Epoch 29/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.5170 - accuracy: 0.7754 - val_loss: 0.5447 - val_accuracy: 0.7891\n",
            "Epoch 30/200\n",
            "14/14 [==============================] - 13s 948ms/step - loss: 0.5122 - accuracy: 0.7860 - val_loss: 0.5678 - val_accuracy: 0.7637\n",
            "Epoch 31/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.5031 - accuracy: 0.7801 - val_loss: 0.5697 - val_accuracy: 0.7676\n",
            "Epoch 32/200\n",
            "14/14 [==============================] - 13s 951ms/step - loss: 0.5102 - accuracy: 0.7779 - val_loss: 0.5646 - val_accuracy: 0.7754\n",
            "Epoch 33/200\n",
            "14/14 [==============================] - 13s 964ms/step - loss: 0.4981 - accuracy: 0.7815 - val_loss: 0.5612 - val_accuracy: 0.7754\n",
            "Epoch 34/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.4983 - accuracy: 0.7888 - val_loss: 0.5427 - val_accuracy: 0.7891\n",
            "Epoch 35/200\n",
            "14/14 [==============================] - 13s 958ms/step - loss: 0.4974 - accuracy: 0.7843 - val_loss: 0.5607 - val_accuracy: 0.7832\n",
            "Epoch 36/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4898 - accuracy: 0.7840 - val_loss: 0.5626 - val_accuracy: 0.7812\n",
            "Epoch 37/200\n",
            "14/14 [==============================] - 13s 963ms/step - loss: 0.4850 - accuracy: 0.7924 - val_loss: 0.5546 - val_accuracy: 0.7832\n",
            "Epoch 38/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4880 - accuracy: 0.7910 - val_loss: 0.5556 - val_accuracy: 0.7832\n",
            "Epoch 39/200\n",
            "14/14 [==============================] - 13s 960ms/step - loss: 0.4763 - accuracy: 0.7927 - val_loss: 0.5612 - val_accuracy: 0.7656\n",
            "Epoch 40/200\n",
            "14/14 [==============================] - 14s 981ms/step - loss: 0.4770 - accuracy: 0.7854 - val_loss: 0.5516 - val_accuracy: 0.7676\n",
            "Epoch 41/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4817 - accuracy: 0.7866 - val_loss: 0.5583 - val_accuracy: 0.7656\n",
            "Epoch 42/200\n",
            "14/14 [==============================] - 13s 954ms/step - loss: 0.4831 - accuracy: 0.7866 - val_loss: 0.5539 - val_accuracy: 0.7773\n",
            "Epoch 43/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4608 - accuracy: 0.7963 - val_loss: 0.5581 - val_accuracy: 0.7852\n",
            "Epoch 44/200\n",
            "14/14 [==============================] - 14s 965ms/step - loss: 0.4687 - accuracy: 0.7921 - val_loss: 0.5623 - val_accuracy: 0.7773\n",
            "Epoch 45/200\n",
            "14/14 [==============================] - 13s 958ms/step - loss: 0.4681 - accuracy: 0.7974 - val_loss: 0.5443 - val_accuracy: 0.7793\n",
            "Epoch 46/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4655 - accuracy: 0.7977 - val_loss: 0.5423 - val_accuracy: 0.7930\n",
            "Epoch 47/200\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.4583 - accuracy: 0.7944 - val_loss: 0.5565 - val_accuracy: 0.7773\n",
            "Epoch 48/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4634 - accuracy: 0.7972 - val_loss: 0.5466 - val_accuracy: 0.7734\n",
            "Epoch 49/200\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.4581 - accuracy: 0.7994 - val_loss: 0.5504 - val_accuracy: 0.7793\n",
            "Epoch 50/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4452 - accuracy: 0.8011 - val_loss: 0.5383 - val_accuracy: 0.7832\n",
            "Epoch 51/200\n",
            "14/14 [==============================] - 13s 951ms/step - loss: 0.4586 - accuracy: 0.7913 - val_loss: 0.5648 - val_accuracy: 0.7637\n",
            "Epoch 52/200\n",
            "14/14 [==============================] - 13s 954ms/step - loss: 0.4441 - accuracy: 0.8022 - val_loss: 0.5453 - val_accuracy: 0.7871\n",
            "Epoch 53/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4467 - accuracy: 0.8030 - val_loss: 0.5629 - val_accuracy: 0.7715\n",
            "Epoch 54/200\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.4396 - accuracy: 0.8013 - val_loss: 0.5585 - val_accuracy: 0.7812\n",
            "Epoch 55/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.4398 - accuracy: 0.8030 - val_loss: 0.5694 - val_accuracy: 0.7695\n",
            "Epoch 56/200\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.4282 - accuracy: 0.8072 - val_loss: 0.5627 - val_accuracy: 0.7715\n",
            "Epoch 57/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.4352 - accuracy: 0.8080 - val_loss: 0.5741 - val_accuracy: 0.7520\n",
            "Epoch 58/200\n",
            "14/14 [==============================] - 13s 958ms/step - loss: 0.4277 - accuracy: 0.8072 - val_loss: 0.5452 - val_accuracy: 0.7793\n",
            "Epoch 59/200\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.4315 - accuracy: 0.8027 - val_loss: 0.5372 - val_accuracy: 0.7754\n",
            "Epoch 60/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.4262 - accuracy: 0.8142 - val_loss: 0.5304 - val_accuracy: 0.7812\n",
            "Epoch 61/200\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.4186 - accuracy: 0.8119 - val_loss: 0.5727 - val_accuracy: 0.7637\n",
            "Epoch 62/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4161 - accuracy: 0.8170 - val_loss: 0.5688 - val_accuracy: 0.7754\n",
            "Epoch 63/200\n",
            "14/14 [==============================] - 13s 952ms/step - loss: 0.4069 - accuracy: 0.8147 - val_loss: 0.5519 - val_accuracy: 0.7891\n",
            "Epoch 64/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4168 - accuracy: 0.8147 - val_loss: 0.5770 - val_accuracy: 0.7852\n",
            "Epoch 65/200\n",
            "14/14 [==============================] - 13s 950ms/step - loss: 0.4052 - accuracy: 0.8200 - val_loss: 0.5716 - val_accuracy: 0.7793\n",
            "Epoch 66/200\n",
            "14/14 [==============================] - 13s 956ms/step - loss: 0.4091 - accuracy: 0.8105 - val_loss: 0.5688 - val_accuracy: 0.7812\n",
            "Epoch 67/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.4048 - accuracy: 0.8195 - val_loss: 0.5727 - val_accuracy: 0.7793\n",
            "Epoch 68/200\n",
            "14/14 [==============================] - 13s 953ms/step - loss: 0.4033 - accuracy: 0.8139 - val_loss: 0.5774 - val_accuracy: 0.7637\n",
            "Epoch 69/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3977 - accuracy: 0.8189 - val_loss: 0.5503 - val_accuracy: 0.7812\n",
            "Epoch 70/200\n",
            "14/14 [==============================] - 13s 948ms/step - loss: 0.4034 - accuracy: 0.8117 - val_loss: 0.5649 - val_accuracy: 0.7754\n",
            "Epoch 71/200\n",
            "14/14 [==============================] - 14s 968ms/step - loss: 0.3961 - accuracy: 0.8228 - val_loss: 0.5813 - val_accuracy: 0.7852\n",
            "Epoch 72/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3888 - accuracy: 0.8203 - val_loss: 0.5792 - val_accuracy: 0.7793\n",
            "Epoch 73/200\n",
            "14/14 [==============================] - 14s 967ms/step - loss: 0.3959 - accuracy: 0.8195 - val_loss: 0.5762 - val_accuracy: 0.7910\n",
            "Epoch 74/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3860 - accuracy: 0.8276 - val_loss: 0.5848 - val_accuracy: 0.7793\n",
            "Epoch 75/200\n",
            "14/14 [==============================] - 14s 984ms/step - loss: 0.3872 - accuracy: 0.8225 - val_loss: 0.5834 - val_accuracy: 0.7715\n",
            "Epoch 76/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3795 - accuracy: 0.8334 - val_loss: 0.5879 - val_accuracy: 0.7793\n",
            "Epoch 77/200\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.3780 - accuracy: 0.8259 - val_loss: 0.5977 - val_accuracy: 0.7812\n",
            "Epoch 78/200\n",
            "14/14 [==============================] - 13s 962ms/step - loss: 0.3789 - accuracy: 0.8273 - val_loss: 0.5949 - val_accuracy: 0.7871\n",
            "Epoch 79/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3813 - accuracy: 0.8256 - val_loss: 0.5669 - val_accuracy: 0.7969\n",
            "Epoch 80/200\n",
            "14/14 [==============================] - 13s 960ms/step - loss: 0.3673 - accuracy: 0.8371 - val_loss: 0.5832 - val_accuracy: 0.7969\n",
            "Epoch 81/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3697 - accuracy: 0.8259 - val_loss: 0.5596 - val_accuracy: 0.7891\n",
            "Epoch 82/200\n",
            "14/14 [==============================] - 13s 962ms/step - loss: 0.3610 - accuracy: 0.8343 - val_loss: 0.6036 - val_accuracy: 0.7793\n",
            "Epoch 83/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.3596 - accuracy: 0.8407 - val_loss: 0.5892 - val_accuracy: 0.7695\n",
            "Epoch 84/200\n",
            "14/14 [==============================] - 13s 951ms/step - loss: 0.3607 - accuracy: 0.8348 - val_loss: 0.6174 - val_accuracy: 0.7754\n",
            "Epoch 85/200\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.3516 - accuracy: 0.8460 - val_loss: 0.6067 - val_accuracy: 0.7812\n",
            "Epoch 86/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.3502 - accuracy: 0.8371 - val_loss: 0.6184 - val_accuracy: 0.7812\n",
            "Epoch 87/200\n",
            "14/14 [==============================] - 13s 954ms/step - loss: 0.3519 - accuracy: 0.8443 - val_loss: 0.6142 - val_accuracy: 0.7793\n",
            "Epoch 88/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3440 - accuracy: 0.8435 - val_loss: 0.6217 - val_accuracy: 0.7871\n",
            "Epoch 89/200\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.3424 - accuracy: 0.8376 - val_loss: 0.6397 - val_accuracy: 0.7793\n",
            "Epoch 90/200\n",
            "14/14 [==============================] - 13s 958ms/step - loss: 0.3432 - accuracy: 0.8451 - val_loss: 0.6415 - val_accuracy: 0.7715\n",
            "Epoch 91/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3431 - accuracy: 0.8424 - val_loss: 0.6141 - val_accuracy: 0.7734\n",
            "Epoch 92/200\n",
            "14/14 [==============================] - 13s 959ms/step - loss: 0.3304 - accuracy: 0.8499 - val_loss: 0.6246 - val_accuracy: 0.7734\n",
            "Epoch 93/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3271 - accuracy: 0.8499 - val_loss: 0.6419 - val_accuracy: 0.7754\n",
            "Epoch 94/200\n",
            "14/14 [==============================] - 13s 953ms/step - loss: 0.3229 - accuracy: 0.8583 - val_loss: 0.6181 - val_accuracy: 0.7773\n",
            "Epoch 95/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.3300 - accuracy: 0.8541 - val_loss: 0.6429 - val_accuracy: 0.7676\n",
            "Epoch 96/200\n",
            "14/14 [==============================] - 13s 953ms/step - loss: 0.3171 - accuracy: 0.8563 - val_loss: 0.6394 - val_accuracy: 0.7793\n",
            "Epoch 97/200\n",
            "14/14 [==============================] - 13s 963ms/step - loss: 0.3253 - accuracy: 0.8571 - val_loss: 0.5846 - val_accuracy: 0.7852\n",
            "Epoch 98/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3184 - accuracy: 0.8546 - val_loss: 0.6635 - val_accuracy: 0.7676\n",
            "Epoch 99/200\n",
            "14/14 [==============================] - 14s 966ms/step - loss: 0.3247 - accuracy: 0.8544 - val_loss: 0.6307 - val_accuracy: 0.7852\n",
            "Epoch 100/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.3140 - accuracy: 0.8566 - val_loss: 0.6430 - val_accuracy: 0.7891\n",
            "Epoch 101/200\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.3053 - accuracy: 0.8585 - val_loss: 0.6548 - val_accuracy: 0.7656\n",
            "Epoch 102/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.3110 - accuracy: 0.8594 - val_loss: 0.6804 - val_accuracy: 0.7656\n",
            "Epoch 103/200\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.3024 - accuracy: 0.8597 - val_loss: 0.6363 - val_accuracy: 0.7812\n",
            "Epoch 104/200\n",
            "14/14 [==============================] - 13s 963ms/step - loss: 0.3018 - accuracy: 0.8627 - val_loss: 0.6649 - val_accuracy: 0.7852\n",
            "Epoch 105/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2956 - accuracy: 0.8630 - val_loss: 0.6657 - val_accuracy: 0.7754\n",
            "Epoch 106/200\n",
            "14/14 [==============================] - 13s 954ms/step - loss: 0.2977 - accuracy: 0.8683 - val_loss: 0.6623 - val_accuracy: 0.7773\n",
            "Epoch 107/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.3083 - accuracy: 0.8599 - val_loss: 0.6808 - val_accuracy: 0.7695\n",
            "Epoch 108/200\n",
            "14/14 [==============================] - 13s 956ms/step - loss: 0.2903 - accuracy: 0.8691 - val_loss: 0.6954 - val_accuracy: 0.7637\n",
            "Epoch 109/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.2839 - accuracy: 0.8744 - val_loss: 0.6765 - val_accuracy: 0.7695\n",
            "Epoch 110/200\n",
            "14/14 [==============================] - 13s 950ms/step - loss: 0.2847 - accuracy: 0.8666 - val_loss: 0.7317 - val_accuracy: 0.7539\n",
            "Epoch 111/200\n",
            "14/14 [==============================] - 13s 947ms/step - loss: 0.2744 - accuracy: 0.8814 - val_loss: 0.6896 - val_accuracy: 0.7773\n",
            "Epoch 112/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.2763 - accuracy: 0.8786 - val_loss: 0.7119 - val_accuracy: 0.7715\n",
            "Epoch 113/200\n",
            "14/14 [==============================] - 14s 969ms/step - loss: 0.2679 - accuracy: 0.8756 - val_loss: 0.6784 - val_accuracy: 0.7637\n",
            "Epoch 114/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2803 - accuracy: 0.8664 - val_loss: 0.7254 - val_accuracy: 0.7617\n",
            "Epoch 115/200\n",
            "14/14 [==============================] - 14s 967ms/step - loss: 0.2684 - accuracy: 0.8825 - val_loss: 0.7699 - val_accuracy: 0.7578\n",
            "Epoch 116/200\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.2726 - accuracy: 0.8834 - val_loss: 0.7453 - val_accuracy: 0.7617\n",
            "Epoch 117/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2631 - accuracy: 0.8825 - val_loss: 0.7827 - val_accuracy: 0.7656\n",
            "Epoch 118/200\n",
            "14/14 [==============================] - 14s 976ms/step - loss: 0.2574 - accuracy: 0.8781 - val_loss: 0.7782 - val_accuracy: 0.7480\n",
            "Epoch 119/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2747 - accuracy: 0.8730 - val_loss: 0.7858 - val_accuracy: 0.7676\n",
            "Epoch 120/200\n",
            "14/14 [==============================] - 13s 959ms/step - loss: 0.2589 - accuracy: 0.8797 - val_loss: 0.7469 - val_accuracy: 0.7734\n",
            "Epoch 121/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.2619 - accuracy: 0.8845 - val_loss: 0.7851 - val_accuracy: 0.7715\n",
            "Epoch 122/200\n",
            "14/14 [==============================] - 13s 957ms/step - loss: 0.2591 - accuracy: 0.8831 - val_loss: 0.7953 - val_accuracy: 0.7715\n",
            "Epoch 123/200\n",
            "14/14 [==============================] - 13s 958ms/step - loss: 0.2426 - accuracy: 0.8887 - val_loss: 0.7979 - val_accuracy: 0.7656\n",
            "Epoch 124/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2564 - accuracy: 0.8842 - val_loss: 0.8075 - val_accuracy: 0.7656\n",
            "Epoch 125/200\n",
            "14/14 [==============================] - 13s 952ms/step - loss: 0.2408 - accuracy: 0.8943 - val_loss: 0.7397 - val_accuracy: 0.7832\n",
            "Epoch 126/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2395 - accuracy: 0.8926 - val_loss: 0.7877 - val_accuracy: 0.7715\n",
            "Epoch 127/200\n",
            "14/14 [==============================] - 13s 960ms/step - loss: 0.2454 - accuracy: 0.8915 - val_loss: 0.8432 - val_accuracy: 0.7754\n",
            "Epoch 128/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2357 - accuracy: 0.8962 - val_loss: 0.8527 - val_accuracy: 0.7578\n",
            "Epoch 129/200\n",
            "14/14 [==============================] - 13s 951ms/step - loss: 0.2411 - accuracy: 0.8962 - val_loss: 0.8280 - val_accuracy: 0.7637\n",
            "Epoch 130/200\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.2312 - accuracy: 0.8948 - val_loss: 0.9133 - val_accuracy: 0.7461\n",
            "Epoch 131/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2342 - accuracy: 0.8920 - val_loss: 0.8350 - val_accuracy: 0.7793\n",
            "Epoch 132/200\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.2221 - accuracy: 0.9004 - val_loss: 0.8467 - val_accuracy: 0.7793\n",
            "Epoch 133/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2146 - accuracy: 0.9049 - val_loss: 0.8970 - val_accuracy: 0.7734\n",
            "Epoch 134/200\n",
            "14/14 [==============================] - 14s 968ms/step - loss: 0.2397 - accuracy: 0.8940 - val_loss: 0.8713 - val_accuracy: 0.7773\n",
            "Epoch 135/200\n",
            "14/14 [==============================] - 14s 965ms/step - loss: 0.2160 - accuracy: 0.9032 - val_loss: 0.8778 - val_accuracy: 0.7695\n",
            "Epoch 136/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.2187 - accuracy: 0.9032 - val_loss: 0.9365 - val_accuracy: 0.7520\n",
            "Epoch 137/200\n",
            "14/14 [==============================] - 13s 951ms/step - loss: 0.2316 - accuracy: 0.8970 - val_loss: 0.9006 - val_accuracy: 0.7637\n",
            "Epoch 138/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2099 - accuracy: 0.9068 - val_loss: 0.8854 - val_accuracy: 0.7715\n",
            "Epoch 139/200\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.2073 - accuracy: 0.9099 - val_loss: 0.9104 - val_accuracy: 0.7637\n",
            "Epoch 140/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.2119 - accuracy: 0.9060 - val_loss: 0.8929 - val_accuracy: 0.7559\n",
            "Epoch 141/200\n",
            "14/14 [==============================] - 14s 967ms/step - loss: 0.2017 - accuracy: 0.9143 - val_loss: 0.9393 - val_accuracy: 0.7539\n",
            "Epoch 142/200\n",
            "14/14 [==============================] - 14s 971ms/step - loss: 0.1947 - accuracy: 0.9121 - val_loss: 0.9424 - val_accuracy: 0.7715\n",
            "Epoch 143/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.2060 - accuracy: 0.9071 - val_loss: 0.9381 - val_accuracy: 0.7715\n",
            "Epoch 144/200\n",
            "14/14 [==============================] - 14s 969ms/step - loss: 0.1984 - accuracy: 0.9113 - val_loss: 0.8437 - val_accuracy: 0.7773\n",
            "Epoch 145/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1968 - accuracy: 0.9121 - val_loss: 0.9274 - val_accuracy: 0.7734\n",
            "Epoch 146/200\n",
            "14/14 [==============================] - 13s 953ms/step - loss: 0.1973 - accuracy: 0.9160 - val_loss: 0.9554 - val_accuracy: 0.7539\n",
            "Epoch 147/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.2068 - accuracy: 0.9096 - val_loss: 0.8826 - val_accuracy: 0.7773\n",
            "Epoch 148/200\n",
            "14/14 [==============================] - 13s 951ms/step - loss: 0.1898 - accuracy: 0.9196 - val_loss: 0.9300 - val_accuracy: 0.7812\n",
            "Epoch 149/200\n",
            "14/14 [==============================] - 13s 962ms/step - loss: 0.1853 - accuracy: 0.9194 - val_loss: 0.9471 - val_accuracy: 0.7695\n",
            "Epoch 150/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.1978 - accuracy: 0.9107 - val_loss: 0.9802 - val_accuracy: 0.7598\n",
            "Epoch 151/200\n",
            "14/14 [==============================] - 13s 956ms/step - loss: 0.1775 - accuracy: 0.9258 - val_loss: 0.9161 - val_accuracy: 0.7754\n",
            "Epoch 152/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1793 - accuracy: 0.9216 - val_loss: 1.0158 - val_accuracy: 0.7637\n",
            "Epoch 153/200\n",
            "14/14 [==============================] - 14s 969ms/step - loss: 0.1917 - accuracy: 0.9116 - val_loss: 0.9376 - val_accuracy: 0.7715\n",
            "Epoch 154/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1716 - accuracy: 0.9291 - val_loss: 1.0105 - val_accuracy: 0.7715\n",
            "Epoch 155/200\n",
            "14/14 [==============================] - 14s 972ms/step - loss: 0.1722 - accuracy: 0.9325 - val_loss: 1.0282 - val_accuracy: 0.7715\n",
            "Epoch 156/200\n",
            "14/14 [==============================] - 13s 960ms/step - loss: 0.1819 - accuracy: 0.9152 - val_loss: 0.9813 - val_accuracy: 0.7715\n",
            "Epoch 157/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1744 - accuracy: 0.9219 - val_loss: 1.0133 - val_accuracy: 0.7754\n",
            "Epoch 158/200\n",
            "14/14 [==============================] - 13s 962ms/step - loss: 0.1768 - accuracy: 0.9205 - val_loss: 0.9890 - val_accuracy: 0.7441\n",
            "Epoch 159/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.1734 - accuracy: 0.9261 - val_loss: 1.0691 - val_accuracy: 0.7598\n",
            "Epoch 160/200\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.1650 - accuracy: 0.9314 - val_loss: 1.0330 - val_accuracy: 0.7637\n",
            "Epoch 161/200\n",
            "14/14 [==============================] - 14s 984ms/step - loss: 0.1644 - accuracy: 0.9302 - val_loss: 1.0350 - val_accuracy: 0.7637\n",
            "Epoch 162/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.1580 - accuracy: 0.9358 - val_loss: 1.1033 - val_accuracy: 0.7578\n",
            "Epoch 163/200\n",
            "14/14 [==============================] - 14s 979ms/step - loss: 0.1661 - accuracy: 0.9280 - val_loss: 1.1064 - val_accuracy: 0.7578\n",
            "Epoch 164/200\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.1640 - accuracy: 0.9249 - val_loss: 1.0905 - val_accuracy: 0.7637\n",
            "Epoch 165/200\n",
            "14/14 [==============================] - 13s 962ms/step - loss: 0.1575 - accuracy: 0.9319 - val_loss: 1.1157 - val_accuracy: 0.7637\n",
            "Epoch 166/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1561 - accuracy: 0.9328 - val_loss: 1.0934 - val_accuracy: 0.7676\n",
            "Epoch 167/200\n",
            "14/14 [==============================] - 14s 966ms/step - loss: 0.1595 - accuracy: 0.9339 - val_loss: 1.0774 - val_accuracy: 0.7793\n",
            "Epoch 168/200\n",
            "14/14 [==============================] - 13s 962ms/step - loss: 0.1558 - accuracy: 0.9333 - val_loss: 1.1062 - val_accuracy: 0.7559\n",
            "Epoch 169/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1487 - accuracy: 0.9425 - val_loss: 1.1013 - val_accuracy: 0.7637\n",
            "Epoch 170/200\n",
            "14/14 [==============================] - 14s 971ms/step - loss: 0.1603 - accuracy: 0.9280 - val_loss: 1.0678 - val_accuracy: 0.7754\n",
            "Epoch 171/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1474 - accuracy: 0.9342 - val_loss: 1.1455 - val_accuracy: 0.7617\n",
            "Epoch 172/200\n",
            "14/14 [==============================] - 14s 981ms/step - loss: 0.1510 - accuracy: 0.9375 - val_loss: 1.0737 - val_accuracy: 0.7715\n",
            "Epoch 173/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1409 - accuracy: 0.9428 - val_loss: 1.1084 - val_accuracy: 0.7656\n",
            "Epoch 174/200\n",
            "14/14 [==============================] - 13s 963ms/step - loss: 0.1406 - accuracy: 0.9386 - val_loss: 1.2083 - val_accuracy: 0.7402\n",
            "Epoch 175/200\n",
            "14/14 [==============================] - 14s 971ms/step - loss: 0.1397 - accuracy: 0.9442 - val_loss: 1.1979 - val_accuracy: 0.7598\n",
            "Epoch 176/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1347 - accuracy: 0.9434 - val_loss: 1.1612 - val_accuracy: 0.7539\n",
            "Epoch 177/200\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.1432 - accuracy: 0.9397 - val_loss: 1.1850 - val_accuracy: 0.7559\n",
            "Epoch 178/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1359 - accuracy: 0.9400 - val_loss: 1.1221 - val_accuracy: 0.7617\n",
            "Epoch 179/200\n",
            "14/14 [==============================] - 13s 962ms/step - loss: 0.1465 - accuracy: 0.9381 - val_loss: 1.2273 - val_accuracy: 0.7617\n",
            "Epoch 180/200\n",
            "14/14 [==============================] - 13s 964ms/step - loss: 0.1412 - accuracy: 0.9425 - val_loss: 1.1451 - val_accuracy: 0.7539\n",
            "Epoch 181/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1355 - accuracy: 0.9450 - val_loss: 1.1671 - val_accuracy: 0.7617\n",
            "Epoch 182/200\n",
            "14/14 [==============================] - 14s 974ms/step - loss: 0.1344 - accuracy: 0.9400 - val_loss: 1.1931 - val_accuracy: 0.7559\n",
            "Epoch 183/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1290 - accuracy: 0.9475 - val_loss: 1.1759 - val_accuracy: 0.7695\n",
            "Epoch 184/200\n",
            "14/14 [==============================] - 14s 967ms/step - loss: 0.1268 - accuracy: 0.9506 - val_loss: 1.2816 - val_accuracy: 0.7520\n",
            "Epoch 185/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1443 - accuracy: 0.9436 - val_loss: 1.1937 - val_accuracy: 0.7734\n",
            "Epoch 186/200\n",
            "14/14 [==============================] - 14s 972ms/step - loss: 0.1238 - accuracy: 0.9503 - val_loss: 1.1889 - val_accuracy: 0.7656\n",
            "Epoch 187/200\n",
            "14/14 [==============================] - 14s 974ms/step - loss: 0.1186 - accuracy: 0.9492 - val_loss: 1.2958 - val_accuracy: 0.7422\n",
            "Epoch 188/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1269 - accuracy: 0.9445 - val_loss: 1.2448 - val_accuracy: 0.7637\n",
            "Epoch 189/200\n",
            "14/14 [==============================] - 14s 971ms/step - loss: 0.1299 - accuracy: 0.9425 - val_loss: 1.2752 - val_accuracy: 0.7422\n",
            "Epoch 190/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1296 - accuracy: 0.9475 - val_loss: 1.2591 - val_accuracy: 0.7695\n",
            "Epoch 191/200\n",
            "14/14 [==============================] - 14s 967ms/step - loss: 0.1225 - accuracy: 0.9467 - val_loss: 1.3021 - val_accuracy: 0.7773\n",
            "Epoch 192/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1286 - accuracy: 0.9470 - val_loss: 1.3357 - val_accuracy: 0.7520\n",
            "Epoch 193/200\n",
            "14/14 [==============================] - 14s 972ms/step - loss: 0.1238 - accuracy: 0.9495 - val_loss: 1.2678 - val_accuracy: 0.7617\n",
            "Epoch 194/200\n",
            "14/14 [==============================] - 13s 964ms/step - loss: 0.1180 - accuracy: 0.9506 - val_loss: 1.3440 - val_accuracy: 0.7422\n",
            "Epoch 195/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1157 - accuracy: 0.9515 - val_loss: 1.3149 - val_accuracy: 0.7598\n",
            "Epoch 196/200\n",
            "14/14 [==============================] - 14s 966ms/step - loss: 0.1262 - accuracy: 0.9481 - val_loss: 1.2466 - val_accuracy: 0.7617\n",
            "Epoch 197/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1101 - accuracy: 0.9568 - val_loss: 1.2781 - val_accuracy: 0.7520\n",
            "Epoch 198/200\n",
            "14/14 [==============================] - 14s 975ms/step - loss: 0.1081 - accuracy: 0.9551 - val_loss: 1.2944 - val_accuracy: 0.7578\n",
            "Epoch 199/200\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.1155 - accuracy: 0.9551 - val_loss: 1.2733 - val_accuracy: 0.7773\n",
            "Epoch 200/200\n",
            "14/14 [==============================] - 14s 973ms/step - loss: 0.1088 - accuracy: 0.9562 - val_loss: 1.2455 - val_accuracy: 0.7539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ExLpzmeQaS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "75980ad9-7214-4c06-db70-fbcd21142a82"
      },
      "source": [
        "test_steps = int(len(df_test)/batch_size)\n",
        "\n",
        "metrics = base_vgg_model.evaluate(test_dataset,\n",
        "                   steps = test_steps)\n",
        "print(\"model accuracy:\",metrics[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9f37aea22d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m metrics = base_vgg_model.evaluate(test_dataset,\n\u001b[1;32m      4\u001b[0m                    steps = test_steps)\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCGpPP-l1J7_",
        "colab_type": "text"
      },
      "source": [
        "## 1st unfreezing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPl0Png5yCQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3),pooling=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z08msq2tyDc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = base_vgg.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# and a logits layer -- let's say we have 3 classes\n",
        "predictions = Dense(3, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whAJkq6qDOfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_vgg_model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in base_vgg_model.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHCq5zulG67p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "30e183ee-7b60-42b1-f392-74d9dd8421ed"
      },
      "source": [
        "for layer in base_vgg_model.layers:\n",
        "    print(layer.name,layer.trainable)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1 False\n",
            "block1_conv1 False\n",
            "block1_conv2 False\n",
            "block1_pool False\n",
            "block2_conv1 False\n",
            "block2_conv2 False\n",
            "block2_pool False\n",
            "block3_conv1 False\n",
            "block3_conv2 False\n",
            "block3_conv3 False\n",
            "block3_pool False\n",
            "block4_conv1 False\n",
            "block4_conv2 False\n",
            "block4_conv3 False\n",
            "block4_pool False\n",
            "block5_conv1 True\n",
            "block5_conv2 True\n",
            "block5_conv3 True\n",
            "block5_pool True\n",
            "global_average_pooling2d True\n",
            "dense True\n",
            "dropout True\n",
            "dense_1 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmgEucTcyPqk",
        "colab_type": "text"
      },
      "source": [
        "#### fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZuKehrVG9L3",
        "colab_type": "code",
        "outputId": "93ce7314-cb74-433f-a71a-e3ecf3a8a763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "\t\n",
        "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=15)\n",
        "\n",
        "vgg_model_filepath = 'small_unfrozen_vgg16.h5'\n",
        "mcp = ModelCheckpoint(vgg_model_filepath, monitor='accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with validation \n",
        "tuned_vgg_history = base_vgg_model.fit( train_dataset, steps_per_epoch = train_steps,\n",
        "                   epochs = epochs,\n",
        "                   validation_data = valid_dataset,\n",
        "                   validation_steps = val_steps,\n",
        "                   callbacks=[es, mcp])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 17 steps, validate for 2 steps\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.4264 - accuracy: 0.8118 - val_loss: 0.4985 - val_accuracy: 0.7871\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3903 - accuracy: 0.8295 - val_loss: 0.5119 - val_accuracy: 0.7832\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.3957 - accuracy: 0.8284 - val_loss: 0.4664 - val_accuracy: 0.8027\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3788 - accuracy: 0.8366 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.3772 - accuracy: 0.8339 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.3631 - accuracy: 0.8470 - val_loss: 0.4850 - val_accuracy: 0.7773\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3543 - accuracy: 0.8502 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.3500 - accuracy: 0.8504 - val_loss: 0.5044 - val_accuracy: 0.7910\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3379 - accuracy: 0.8559 - val_loss: 0.4972 - val_accuracy: 0.7793\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 19s 1s/step - loss: 0.3376 - accuracy: 0.8575 - val_loss: 0.5065 - val_accuracy: 0.7852\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.3226 - accuracy: 0.8670 - val_loss: 0.5279 - val_accuracy: 0.7695\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.3239 - accuracy: 0.8628 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3167 - accuracy: 0.8672 - val_loss: 0.4894 - val_accuracy: 0.8008\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.3072 - accuracy: 0.8725 - val_loss: 0.5082 - val_accuracy: 0.7871\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.3056 - accuracy: 0.8745 - val_loss: 0.5067 - val_accuracy: 0.7949\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2988 - accuracy: 0.8722 - val_loss: 0.5469 - val_accuracy: 0.7773\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2906 - accuracy: 0.8798 - val_loss: 0.5121 - val_accuracy: 0.7793\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2757 - accuracy: 0.8869 - val_loss: 0.5442 - val_accuracy: 0.7930\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2799 - accuracy: 0.8849 - val_loss: 0.5074 - val_accuracy: 0.7910\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.2846 - accuracy: 0.8817 - val_loss: 0.5532 - val_accuracy: 0.7695\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.2575 - accuracy: 0.8957 - val_loss: 0.4972 - val_accuracy: 0.7832\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2588 - accuracy: 0.8991 - val_loss: 0.5310 - val_accuracy: 0.7832\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.2612 - accuracy: 0.8833 - val_loss: 0.5394 - val_accuracy: 0.7754\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2573 - accuracy: 0.8959 - val_loss: 0.5451 - val_accuracy: 0.7871\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.2476 - accuracy: 0.8987 - val_loss: 0.5845 - val_accuracy: 0.7734\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2471 - accuracy: 0.9028 - val_loss: 0.5742 - val_accuracy: 0.7637\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2461 - accuracy: 0.8987 - val_loss: 0.5689 - val_accuracy: 0.7852\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.2428 - accuracy: 0.9003 - val_loss: 0.5940 - val_accuracy: 0.7871\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2411 - accuracy: 0.9014 - val_loss: 0.5433 - val_accuracy: 0.7871\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2353 - accuracy: 0.9035 - val_loss: 0.5878 - val_accuracy: 0.7695\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2256 - accuracy: 0.9088 - val_loss: 0.5501 - val_accuracy: 0.7812\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.2148 - accuracy: 0.9125 - val_loss: 0.5144 - val_accuracy: 0.7812\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2197 - accuracy: 0.9136 - val_loss: 0.6047 - val_accuracy: 0.7891\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2151 - accuracy: 0.9104 - val_loss: 0.5859 - val_accuracy: 0.7969\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.2088 - accuracy: 0.9187 - val_loss: 0.5262 - val_accuracy: 0.7793\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.2043 - accuracy: 0.9205 - val_loss: 0.6117 - val_accuracy: 0.7637\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2082 - accuracy: 0.9131 - val_loss: 0.6182 - val_accuracy: 0.7695\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1976 - accuracy: 0.9189 - val_loss: 0.6132 - val_accuracy: 0.8008\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.2033 - accuracy: 0.9193 - val_loss: 0.6001 - val_accuracy: 0.7637\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2042 - accuracy: 0.9177 - val_loss: 0.5944 - val_accuracy: 0.7988\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 19s 1s/step - loss: 0.1880 - accuracy: 0.9274 - val_loss: 0.6483 - val_accuracy: 0.7734\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1910 - accuracy: 0.9200 - val_loss: 0.7141 - val_accuracy: 0.7559\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1821 - accuracy: 0.9297 - val_loss: 0.6395 - val_accuracy: 0.7773\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1870 - accuracy: 0.9237 - val_loss: 0.6242 - val_accuracy: 0.7715\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1869 - accuracy: 0.9281 - val_loss: 0.6063 - val_accuracy: 0.7734\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1785 - accuracy: 0.9295 - val_loss: 0.5476 - val_accuracy: 0.7910\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1742 - accuracy: 0.9301 - val_loss: 0.7089 - val_accuracy: 0.7695\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1760 - accuracy: 0.9258 - val_loss: 0.6498 - val_accuracy: 0.7832\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1660 - accuracy: 0.9375 - val_loss: 0.6856 - val_accuracy: 0.7715\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1715 - accuracy: 0.9308 - val_loss: 0.6621 - val_accuracy: 0.7637\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1618 - accuracy: 0.9393 - val_loss: 0.6969 - val_accuracy: 0.7617\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1675 - accuracy: 0.9327 - val_loss: 0.5898 - val_accuracy: 0.7695\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 25s 1s/step - loss: 0.1527 - accuracy: 0.9416 - val_loss: 0.6676 - val_accuracy: 0.7676\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1628 - accuracy: 0.9396 - val_loss: 0.6829 - val_accuracy: 0.7734\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1558 - accuracy: 0.9405 - val_loss: 0.6795 - val_accuracy: 0.7871\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1607 - accuracy: 0.9382 - val_loss: 0.7119 - val_accuracy: 0.7715\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 19s 1s/step - loss: 0.1519 - accuracy: 0.9423 - val_loss: 0.6378 - val_accuracy: 0.7656\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1554 - accuracy: 0.9396 - val_loss: 0.7030 - val_accuracy: 0.7734\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1528 - accuracy: 0.9386 - val_loss: 0.6244 - val_accuracy: 0.7969\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1563 - accuracy: 0.9370 - val_loss: 0.6633 - val_accuracy: 0.7676\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.1468 - accuracy: 0.9444 - val_loss: 0.7453 - val_accuracy: 0.7520\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1414 - accuracy: 0.9449 - val_loss: 0.7213 - val_accuracy: 0.7832\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1472 - accuracy: 0.9409 - val_loss: 0.6678 - val_accuracy: 0.8008\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1386 - accuracy: 0.9490 - val_loss: 0.7037 - val_accuracy: 0.7656\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1386 - accuracy: 0.9485 - val_loss: 0.7492 - val_accuracy: 0.7676\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.1328 - accuracy: 0.9529 - val_loss: 0.8169 - val_accuracy: 0.7617\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1305 - accuracy: 0.9515 - val_loss: 0.7497 - val_accuracy: 0.7617\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1316 - accuracy: 0.9488 - val_loss: 0.8522 - val_accuracy: 0.7305\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1350 - accuracy: 0.9455 - val_loss: 0.7270 - val_accuracy: 0.7734\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1313 - accuracy: 0.9511 - val_loss: 0.7023 - val_accuracy: 0.7832\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1344 - accuracy: 0.9481 - val_loss: 0.7644 - val_accuracy: 0.7676\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1195 - accuracy: 0.9545 - val_loss: 0.7257 - val_accuracy: 0.7949\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1253 - accuracy: 0.9490 - val_loss: 0.7671 - val_accuracy: 0.7910\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1378 - accuracy: 0.9442 - val_loss: 0.7050 - val_accuracy: 0.7930\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1231 - accuracy: 0.9552 - val_loss: 0.8207 - val_accuracy: 0.7695\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.1193 - accuracy: 0.9563 - val_loss: 0.8125 - val_accuracy: 0.7520\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1220 - accuracy: 0.9543 - val_loss: 0.7588 - val_accuracy: 0.7812\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.1253 - accuracy: 0.9517 - val_loss: 0.8292 - val_accuracy: 0.7520\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.1145 - accuracy: 0.9570 - val_loss: 0.7949 - val_accuracy: 0.7656\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1126 - accuracy: 0.9584 - val_loss: 0.7197 - val_accuracy: 0.7930\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1161 - accuracy: 0.9591 - val_loss: 0.7948 - val_accuracy: 0.7812\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1132 - accuracy: 0.9563 - val_loss: 0.8364 - val_accuracy: 0.7676\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1068 - accuracy: 0.9598 - val_loss: 0.7539 - val_accuracy: 0.7793\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1121 - accuracy: 0.9577 - val_loss: 0.8015 - val_accuracy: 0.7734\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 18s 1s/step - loss: 0.1050 - accuracy: 0.9632 - val_loss: 0.8746 - val_accuracy: 0.7637\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 16s 950ms/step - loss: 0.1111 - accuracy: 0.9577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-5940296f0000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                    \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                    callbacks=[es, mcp])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    387\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    388\u001b[0m                                  prefix='val_')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2293\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2295\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1554\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1555\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1556\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1635\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1637\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1638\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1639\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRA10E4Zhjwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_vgg_model.save(cwd + '/models/vgg_tuned.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTJmv9z6iQyI",
        "colab_type": "code",
        "outputId": "db695887-a700-4861-a21f-e47910e174ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "best_vgg_model = load_model(cwd + '/models/vgg_tuned.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LARhhZGYyTV9",
        "colab_type": "text"
      },
      "source": [
        "#### saving the history of the fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whH3xT9KT1Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(cwd + '/trainHistoryDict/vgg_history.p', 'wb') as file_pi:\n",
        "        pickle.dump(tuned_vgg_history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwzmuBOAHCFn",
        "colab_type": "code",
        "outputId": "f63c0306-9a32-4f51-ec3b-9b1fe8fb6bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "best_vgg_model = load_model(vgg_model_filepath)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgDMCMdBHsqD",
        "colab_type": "code",
        "outputId": "4a6e203a-c8d1-45c2-decc-4a204ece1e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "test_steps = int(len(df_test)/batch_size)\n",
        "\n",
        "metrics = best_vgg_model.evaluate(test_dataset,\n",
        "                   steps = test_steps)\n",
        "print(\"model accuracy:\",metrics[1])\n",
        "\n",
        "metrics = base_vgg_model.evaluate(test_dataset,\n",
        "                   steps = test_steps)\n",
        "print(\"model accuracy:\",metrics[1])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 3s 1s/step - loss: 0.8058 - accuracy: 0.7754\n",
            "model accuracy: 0.7753906\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.8219 - accuracy: 0.7852\n",
            "model accuracy: 0.78515625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc8aG9-Yi8rR",
        "colab_type": "code",
        "outputId": "1d0e614c-31dc-474d-b866-182d0c7b2518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "11584/15000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7722666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvuqRZujjzE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdsCsXkOu7mF",
        "colab_type": "text"
      },
      "source": [
        "## entirely unfrozen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bbe8e81b-ded2-4b98-cefd-8edeac0e2e74",
        "id": "FrR6YujPvAhK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "base_vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3),pooling=None)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns4VViV9vBTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = base_vgg.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# and a logits layer -- let's say we have 3 classes\n",
        "predictions = Dense(3, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lstePI_NvN-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the model we will train\n",
        "unfrozen_vgg_model = Model(inputs=base_vgg.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DulDS0ovX2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "0df6d296-e582-4c65-8528-d5f386061176"
      },
      "source": [
        "for layer in unfrozen_vgg_model.layers:\n",
        "    print(layer.name)\n",
        "    layer.trainable = True"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n",
            "global_average_pooling2d\n",
            "dense\n",
            "dropout\n",
            "dense_1\n",
            "dropout_1\n",
            "dense_2\n",
            "dropout_2\n",
            "dense_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB5aU4CSvgE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "13d4f3be-d430-46d0-e997-2e60931b83b0"
      },
      "source": [
        "for layer in unfrozen_vgg_model.layers:\n",
        "    print(layer.name,' Trainable =',layer.trainable)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1  Trainable = True\n",
            "block1_conv1  Trainable = True\n",
            "block1_conv2  Trainable = True\n",
            "block1_pool  Trainable = True\n",
            "block2_conv1  Trainable = True\n",
            "block2_conv2  Trainable = True\n",
            "block2_pool  Trainable = True\n",
            "block3_conv1  Trainable = True\n",
            "block3_conv2  Trainable = True\n",
            "block3_conv3  Trainable = True\n",
            "block3_pool  Trainable = True\n",
            "block4_conv1  Trainable = True\n",
            "block4_conv2  Trainable = True\n",
            "block4_conv3  Trainable = True\n",
            "block4_pool  Trainable = True\n",
            "block5_conv1  Trainable = True\n",
            "block5_conv2  Trainable = True\n",
            "block5_conv3  Trainable = True\n",
            "block5_pool  Trainable = True\n",
            "global_average_pooling2d  Trainable = True\n",
            "dense  Trainable = True\n",
            "dropout  Trainable = True\n",
            "dense_1  Trainable = True\n",
            "dropout_1  Trainable = True\n",
            "dense_2  Trainable = True\n",
            "dropout_2  Trainable = True\n",
            "dense_3  Trainable = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbqL6LGoxGgT",
        "colab_type": "text"
      },
      "source": [
        "#### setting the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh4CDz20vo7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "unfrozen_vgg_model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5lKCJYwwhkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b9647f81-a5b0-49cb-edbe-89a135c42f35"
      },
      "source": [
        "train_steps = int(len(df)/batch_size) #total trains set / batch_size\n",
        "val_steps = int(len(df_val)/batch_size)\n",
        "\n",
        "print('train steps:',train_steps)\n",
        "print('val steps:',val_steps)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train steps: 14\n",
            "val steps: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vJQLMr9w64c",
        "colab_type": "text"
      },
      "source": [
        "#### fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZFZayCIv6Oo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "e2015f5a-ae25-4fc2-9523-b92e58f35e65"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "\t\n",
        "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=50)\n",
        "\n",
        "vgg_model_filepath = 'unfrozen_vgg16.h5'\n",
        "mcp = ModelCheckpoint(vgg_model_filepath, monitor='accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model with validation \n",
        "unfrozen_vgg_history = unfrozen_vgg_model.fit( train_dataset, steps_per_epoch = train_steps,\n",
        "                   epochs = epochs,\n",
        "                   validation_data = valid_dataset,\n",
        "                   validation_steps = val_steps,\n",
        "                   callbacks=[es, mcp])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 14 steps, validate for 2 steps\n",
            "Epoch 1/50\n",
            "14/14 [==============================] - 1113s 80s/step - loss: 2.2100 - accuracy: 0.3401 - val_loss: 1.0983 - val_accuracy: 0.3809\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.1155 - accuracy: 0.3373 - val_loss: 1.0982 - val_accuracy: 0.3457\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 36s 3s/step - loss: 1.2143 - accuracy: 0.3451 - val_loss: 1.0985 - val_accuracy: 0.3418\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.1688 - accuracy: 0.3295 - val_loss: 1.0986 - val_accuracy: 0.3398\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 33s 2s/step - loss: 1.0988 - accuracy: 0.3304 - val_loss: 1.0987 - val_accuracy: 0.3340\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.0985 - accuracy: 0.3329 - val_loss: 1.0986 - val_accuracy: 0.3281\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.0984 - accuracy: 0.3410 - val_loss: 1.0985 - val_accuracy: 0.3320\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 33s 2s/step - loss: 1.0987 - accuracy: 0.3362 - val_loss: 1.0988 - val_accuracy: 0.3223\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.0985 - accuracy: 0.3404 - val_loss: 1.0985 - val_accuracy: 0.3340\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 33s 2s/step - loss: 1.0985 - accuracy: 0.3396 - val_loss: 1.0988 - val_accuracy: 0.3262\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.0985 - accuracy: 0.3343 - val_loss: 1.0988 - val_accuracy: 0.3281\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 35s 2s/step - loss: 1.0985 - accuracy: 0.3454 - val_loss: 1.0987 - val_accuracy: 0.3359\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.0982 - accuracy: 0.3451 - val_loss: 1.0986 - val_accuracy: 0.3379\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 29s 2s/step - loss: 1.0986 - accuracy: 0.3365 - val_loss: 1.0985 - val_accuracy: 0.3398\n",
            "Epoch 15/50\n",
            " 1/14 [=>............................] - ETA: 1:14WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: \n",
            "WARNING:tensorflow:Can save best model only with accuracy available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-6d515ebda607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                    \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                    callbacks=[es, mcp])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    807\u001b[0m   \"\"\"\n\u001b[1;32m    808\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrepresentable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \"\"\"\n\u001b[0;32m--> 938\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih3vofhBw90T",
        "colab_type": "text"
      },
      "source": [
        "#### saving the history of the fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IKqpLg2wbi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(cwd + '/trainHistoryDict/vgg_history.p', 'wb') as file_pi:\n",
        "        pickle.dump(tuned_vgg_history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}